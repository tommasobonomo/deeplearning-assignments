{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practical_5_1_2_Aspect_Level_Sentiment_ANSWER.ipynb","provenance":[],"collapsed_sections":["uaWk1GuHvpB1","-ZIcsq-SvpCF"]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ph91TE5lvthU","colab_type":"code","outputId":"588cbdf7-3e79-4b92-d961-d3c081cf7b89","executionInfo":{"status":"ok","timestamp":1589831842033,"user_tz":-120,"elapsed":26717,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q7BivIvvvzaW","colab_type":"code","colab":{}},"source":["# You will need to change the following directory path according to your own path\n","#cd drive/My Drive/Recsys-2019/sequence_classifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P0VnIJhDRpvc","colab":{}},"source":["import os\n","import sys\n","import codecs\n","import operator\n","import numpy as np\n","import re\n","from time import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lM1cs7o-vpAW","colab_type":"code","colab":{}},"source":["import _pickle as cPickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UPslRReavpAZ","colab_type":"code","colab":{}},"source":["aspect_path = '/drive/My Drive/Deep Learing Course/practice-5-data/aspect_level-sentiment/aspect_level/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkm19_52vpAd","colab_type":"code","colab":{}},"source":["doc_path = '/drive/My Drive/Deep Learing Course/practice-5-data/doc_level-sentiment/doc_level/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gl50euzvDcQP","colab":{}},"source":["### Reading preprocess data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Sk_RKQSvpAj","colab_type":"code","colab":{}},"source":["def read_pickle(data_path, file_name):\n","\n","    f = open(os.path.join(data_path, file_name), 'rb')\n","    read_file = cPickle.load(f)\n","    f.close()\n","\n","    return read_file\n","\n","def save_pickle(data_path, file_name, data):\n","\n","    f = open(os.path.join(data_path, file_name), 'wb')\n","    cPickle.dump(data, f)\n","    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n","    f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwVGqOSavpAm","colab_type":"code","colab":{}},"source":["vocab = read_pickle(aspect_path, 'all_vocab.pkl')\n","\n","train_x = read_pickle(aspect_path, 'train_x.pkl')\n","train_y = read_pickle(aspect_path, 'train_y.pkl')\n","dev_x = read_pickle(aspect_path, 'dev_x.pkl')\n","dev_y = read_pickle(aspect_path, 'dev_y.pkl')\n","test_x = read_pickle(aspect_path, 'test_x.pkl')\n","test_y = read_pickle(aspect_path, 'test_y.pkl')\n","\n","train_aspect = read_pickle(aspect_path, 'train_aspect.pkl')\n","dev_aspect = read_pickle(aspect_path, 'dev_aspect.pkl')\n","test_aspect = read_pickle(aspect_path, 'test_aspect.pkl')\n","\n","\n","pretrain_data = read_pickle(aspect_path, 'pretrain_data.pkl')\n","pretrain_label = read_pickle(aspect_path, 'pretrain_label.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBmfsDKdvpAu","colab_type":"text"},"source":["### Batch generator and data iterator "]},{"cell_type":"code","metadata":{"id":"p_b-5_EPvpAv","colab_type":"code","colab":{}},"source":["class Dataiterator():\n","    '''\n","      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n","      2) Access to the entire dataset using all()\n","    '''\n","    \n","    def __init__(self, aspect_data, doc_data, seq_length=32, decoder_dim=300, batch_size=32):\n","        \n","        len_aspect_data = len(aspect_data[0])\n","        self.len_doc_data = len(doc_data[0])\n","        \n","        self.X_aspect = aspect_data[0] \n","        self.y_aspect = aspect_data[1]\n","        self.aspect_terms = aspect_data[2]\n","        \n","        self.X_doc = doc_data[0]\n","        self.y_doc = doc_data[1]\n","        \n","        self.num_data = len_aspect_data\n","        self.batch_size = batch_size # batch size\n","        self.reset() # initial: shuffling examples and set index to 0\n","    \n","    def __iter__(self): # iterates data\n","        return self\n","\n","\n","    def reset(self): # initials\n","        self.idx = 0\n","        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n","        \n","    def __next__(self): # return model inputs - outputs per batch\n","        \n","        X_ids = [] # hold ids per batch \n","        while len(X_ids) < self.batch_size:\n","            X_id = self.order[self.idx] # copy random id from initial shuffling\n","            X_ids.append(X_id)\n","            self.idx += 1 # \n","            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n","                self.reset()\n","                raise StopIteration()\n","                \n","        batch_X_aspect = self.X_aspect[np.array(X_ids)] # X values (encoder input) per batch\n","        batch_y_aspect = self.y_aspect[np.array(X_ids)] # y_in values (decoder input) per batch\n","        batch_aspect_terms = self.aspect_terms[np.array(X_ids)]\n","        indices_2 = np.random.choice(self.len_doc_data, self.batch_size)\n","        batch_X_doc = self.X_doc[indices_2]\n","        batch_y_doc = self.y_doc[indices_2]\n","        \n","        \n","        return batch_X_aspect, batch_y_aspect, batch_aspect_terms, batch_X_doc, batch_y_doc\n","\n","          \n","    def all(self): # return all data examples\n","        return self.X_aspect, self.y_aspect, self.aspect_terms, self.X_doc, self.y_doc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sklA6jSUWDS6"},"source":["### Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vDU0hXVJ1PR5","colab":{}},"source":["from keras.models import Model\n","from keras.layers import Input, Embedding, Dense, Lambda, Dropout, LSTM\n","from keras.layers import Reshape, Activation, RepeatVector, concatenate, Concatenate, Dot, Multiply"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pvg-Uf2h_6Qm","colab":{}},"source":["import keras.backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Dnbn0_O0XlGf"},"source":["### Attention Network"]},{"cell_type":"code","metadata":{"id":"yraOrwX3vpA8","colab_type":"code","colab":{}},"source":["overal_maxlen = 82\n","overal_maxlen_aspect = 7"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zjiAsayW1zx9","colab":{}},"source":["class Custom_softmax(Layer):\n","  \n","    def __init__(self, mask_zero=True, **kwargs):\n","        self.mask_zero = mask_zero\n","        self.supports_masking = True\n","        super(Custom_softmax, self).__init__(**kwargs)\n","\n","    def call(self, x,mask=None):\n","        if self.mask_zero:\n","            a = K.exp(x)         \n","            mask = K.cast(mask, K.floatx())\n","            mask = K.expand_dims(mask)\n","            a = a * mask\n","            a=a / (K.sum(a, axis=1, keepdims=True) + K.epsilon())\n","            return a\n","        else:\n","            return K.softmax(x, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[1],1)\n","    \n","    def compute_mask(self, x, mask):\n","        return None\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Bp5xh27GXmva","colab":{}},"source":["repeator = RepeatVector(overal_maxlen, name='repeator_att')\n","concatenator = Concatenate(axis=-1, name='concator_att')\n","densor1 = Dense(300, activation = \"tanh\", name='densor1_att')\n","densor2 = Dense(1, activation = \"relu\", name='densor2_att')\n","activator = Custom_softmax(mask_zero=True,name='softmax_att')\n","dotor = Dot(axes = 1, name='dotor_att')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VH3g4z6R8O3_","colab":{}},"source":["########################################################################################################################################\n","#### Shape of Keys:[batch-size, overal-maxlen,Dimension_output_lstm], Shape of query: [batch-size,1,Dimension-output-wordEmbedding]  ###\n","########################################################################################################################################\n","def attention(keys, query):\n","    \n","    query = repeator(query)\n","    print(\"query shape: %s\" %str(query._keras_shape))\n","    concat = concatenator([keys, query])\n","    print(\"concat shape: %s\" %str(concat._keras_shape))\n","    e1 = densor1(concat)\n","    print(\"e1 shape: %s\" %str(e1._keras_shape))\n","    e2 = densor2(e1)\n","    print(\"e2 shape: %s\" %str(e2._keras_shape))\n","    alphas = activator(e2)\n","    print(\"alphas shape: %s\" %str(alphas._keras_shape))\n","    context = dotor([alphas, keys])\n","    print(\"context shape: %s\" %str(context._keras_shape))\n","    \n","    return context, alphas"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gVmvIn0X_0Ji","colab":{}},"source":["class Average(Layer):\n","  \n","    def __init__(self, mask_zero=True, **kwargs):\n","        self.mask_zero = mask_zero\n","        self.supports_masking = True\n","        super(Average, self).__init__(**kwargs)\n","\n","    def call(self, x,mask=None):\n","        if self.mask_zero:           \n","            mask = K.cast(mask, K.floatx())\n","            mask = K.expand_dims(mask)\n","            x = x * mask\n","            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n","        else:\n","            return K.mean(x, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[-1])\n","    \n","    def compute_mask(self, x, mask):\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TsyFHokczuvO"},"source":["### Main model"]},{"cell_type":"code","metadata":{"id":"pBdo6q2QvpBW","colab_type":"code","colab":{}},"source":["dropout = 0.5     \n","recurrent_dropout = 0.1\n","vocab_size = len(vocab)\n","num_outputs = 3 # labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xQVV-MRRvpBc","colab_type":"text"},"source":["### Inputs: How many inputs do you need for the current task?"]},{"cell_type":"code","metadata":{"id":"eJ7tv-7GvpBd","colab_type":"code","colab":{}},"source":["##### Inputs #####\n","sentence_input = Input(shape=(overal_maxlen,), dtype='int32', name='sentence_input')\n","aspect_input = Input(shape=(overal_maxlen_aspect,), dtype='int32', name='aspect_input')\n","pretrain_input = Input(shape=(None,), dtype='int32', name='pretrain_input')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58PLwihDvpBk","colab_type":"text"},"source":["### Word-level embedding (shareable between all model inputs)"]},{"cell_type":"code","metadata":{"id":"wJxzja4GvpBm","colab_type":"code","colab":{}},"source":["##### construct word embedding layer #####\n","word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uaWk1GuHvpB1","colab_type":"text"},"source":["### Aspect-level representation (averaged)"]},{"cell_type":"code","metadata":{"id":"Q9q7v6TyvpB2","colab_type":"code","outputId":"bb35d09a-92b8-463e-ac98-f75f39092a75","executionInfo":{"status":"ok","timestamp":1589836858720,"user_tz":-120,"elapsed":711,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["### represent aspect as averaged word embedding ###\n","print ('use average term embs as aspect embedding')\n","aspect_term_embs = word_emb(aspect_input)\n","aspect_embs = Average(mask_zero=True, name='aspect_emb')(aspect_term_embs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["use average term embs as aspect embedding\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ZIcsq-SvpCF","colab_type":"text"},"source":["### Sentence-level representation from two domains"]},{"cell_type":"code","metadata":{"id":"lRCN6JX4vpCH","colab_type":"code","colab":{}},"source":["### sentence representation ###\n","sentence_embs = word_emb(sentence_input) # from aspect-level domain\n","pretrain_embs = word_emb(pretrain_input) # from document-level domain"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MzAALsZMrxM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7wvA7CahvpCL","colab_type":"text"},"source":["### LSTM layer (shared between three representations)"]},{"cell_type":"code","metadata":{"id":"FEJg_StjvpCN","colab_type":"code","colab":{}},"source":["rnn = LSTM(300, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout, name='lstm')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JpWf9bQvpCR","colab_type":"code","outputId":"7d9bb6be-f363-4c45-8437-ef02daa452b1","executionInfo":{"status":"ok","timestamp":1589836863113,"user_tz":-120,"elapsed":1094,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["### sentence representation ###\n","sentence_lstm = rnn(sentence_embs)    # from aspect-level domain\n","pretrain_lstm = rnn(pretrain_embs)     # from document-level domain\n","print(sentence_lstm.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 82, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AtrvodzrvpCV","colab_type":"code","colab":{}},"source":["# UNCOMMENT REPLACE KEYS?, QUERY? WITH THE CORRESPONDING TENSORS AS ATTENTION KEYS AND QUERY\n","\n","#att_context, att_weights = attention(KEYS?, QUERY?)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnYbFaqPvpCX","colab_type":"code","outputId":"0c8343cc-01dd-4aa8-9a1c-c8097eb22e13","executionInfo":{"status":"ok","timestamp":1589836863930,"user_tz":-120,"elapsed":475,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["att_context,att_weights=attention(sentence_lstm,aspect_embs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["query shape: (None, 82, 300)\n","concat shape: (None, 82, 600)\n","e1 shape: (None, 82, 300)\n","e2 shape: (None, 82, 1)\n","alphas shape: (None, 82, 1)\n","context shape: (None, 1, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wmAFYpc5vpCa","colab_type":"code","outputId":"6da36aef-f6cd-4e06-c221-8166bb62b5d1","executionInfo":{"status":"ok","timestamp":1589836865359,"user_tz":-120,"elapsed":826,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["pretrain_avg = Average(mask_zero=True)(pretrain_lstm)\n","print(att_context.shape)\n","print(pretrain_avg.shape)\n","sentence_output = Dense(num_outputs, name='dense_1')(att_context)\n","pretrain_output = Dense(num_outputs, name='dense_2')(pretrain_avg)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 1, 300)\n","(None, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rAlpreOvvpCd","colab_type":"code","outputId":"77095032-5624-44c4-f98e-b452f2c36217","executionInfo":{"status":"ok","timestamp":1589836865361,"user_tz":-120,"elapsed":309,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(\"sentence_output shape: %s\" % str(sentence_output._keras_shape))\n","print(pretrain_output.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["sentence_output shape: (None, 1, 3)\n","(None, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T74EglluvpCh","colab_type":"code","colab":{}},"source":["sentence_output = Reshape((num_outputs,))(sentence_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAFar6sZvpCl","colab_type":"code","outputId":"b7aeaf64-6113-4581-f6e5-e1570c074ecd","executionInfo":{"status":"ok","timestamp":1589836867823,"user_tz":-120,"elapsed":1747,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"sentence_output shape: %s\" % str(sentence_output._keras_shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["sentence_output shape: (None, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6_EmohJBvpCr","colab_type":"code","colab":{}},"source":["aspect_probs = Activation('softmax', name='aspect_model')(sentence_output)\n","doc_probs = Activation('softmax', name='pretrain_model')(pretrain_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c6ptr7iuWIYT","colab":{}},"source":["model = Model(inputs=[sentence_input, aspect_input, pretrain_input], outputs=[aspect_probs, doc_probs])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bmPSF8IAENj_","colab":{}},"source":["import keras.optimizers as opt\n","\n","optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eiFkEy-eVtoU","outputId":"93221eea-e36d-47bf-9b6e-583fe601223d","executionInfo":{"status":"ok","timestamp":1589836868034,"user_tz":-120,"elapsed":777,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":887}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","sentence_input (InputLayer)     (None, 82)           0                                            \n","__________________________________________________________________________________________________\n","aspect_input (InputLayer)       (None, 7)            0                                            \n","__________________________________________________________________________________________________\n","word_emb (Embedding)            multiple             3000900     aspect_input[0][0]               \n","                                                                 sentence_input[0][0]             \n","                                                                 pretrain_input[0][0]             \n","__________________________________________________________________________________________________\n","aspect_emb (Average)            (None, 300)          0           word_emb[0][0]                   \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     multiple             721200      word_emb[1][0]                   \n","                                                                 word_emb[2][0]                   \n","__________________________________________________________________________________________________\n","repeator_att (RepeatVector)     (None, 82, 300)      0           aspect_emb[0][0]                 \n","__________________________________________________________________________________________________\n","concator_att (Concatenate)      (None, 82, 600)      0           lstm[0][0]                       \n","                                                                 repeator_att[0][0]               \n","__________________________________________________________________________________________________\n","densor1_att (Dense)             (None, 82, 300)      180300      concator_att[0][0]               \n","__________________________________________________________________________________________________\n","densor2_att (Dense)             (None, 82, 1)        301         densor1_att[0][0]                \n","__________________________________________________________________________________________________\n","pretrain_input (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","softmax_att (Custom_softmax)    (None, 82, 1)        0           densor2_att[0][0]                \n","__________________________________________________________________________________________________\n","dotor_att (Dot)                 (None, 1, 300)       0           softmax_att[0][0]                \n","                                                                 lstm[0][0]                       \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1, 3)         903         dotor_att[0][0]                  \n","__________________________________________________________________________________________________\n","average_3 (Average)             (None, 300)          0           lstm[1][0]                       \n","__________________________________________________________________________________________________\n","reshape_6 (Reshape)             (None, 3)            0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 3)            903         average_3[0][0]                  \n","__________________________________________________________________________________________________\n","aspect_model (Activation)       (None, 3)            0           reshape_6[0][0]                  \n","__________________________________________________________________________________________________\n","pretrain_model (Activation)     (None, 3)            0           dense_2[0][0]                    \n","==================================================================================================\n","Total params: 3,904,507\n","Trainable params: 3,904,507\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FaNcPdHiC650","colab":{}},"source":["model.compile(optimizer=optimizer,\n","              loss={'aspect_model': 'categorical_crossentropy', 'pretrain_model': 'categorical_crossentropy'},\n","              loss_weights = {'aspect_model': 1, 'pretrain_model': 0.1},\n","              metrics = {'aspect_model': 'categorical_accuracy', 'pretrain_model': 'categorical_accuracy'})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ilIKUGn_DEgB"},"source":["### Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Xi0coTFsDWFG","colab":{}},"source":["batch_size = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xETYnVpgvpC5","colab_type":"code","outputId":"1a1d4276-83bf-4426-80ec-432a1ddf8d3e","executionInfo":{"status":"ok","timestamp":1589836872289,"user_tz":-120,"elapsed":455,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pretrain_data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(30000, 300)"]},"metadata":{"tags":[]},"execution_count":206}]},{"cell_type":"code","metadata":{"id":"HviIfa5lvpC7","colab_type":"code","colab":{}},"source":["pretrain_data= np.array(pretrain_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5Y3_eO4QgyC3","colab":{}},"source":["train_steps_epoch = len(train_x)/batch_size\n","batch_train_iter = Dataiterator([train_x, train_y, train_aspect], \\\n","                                [pretrain_data, pretrain_label], batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NvFUoJlvpDA","colab_type":"code","colab":{}},"source":["val_steps_epoch = len(dev_x)/batch_size\n","batch_val_iter = Dataiterator([dev_x, dev_y, dev_aspect], \\\n","                              [pretrain_data, pretrain_label], batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vVb-obDevpDD","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","def train_generator(model, batch_train_iter, batch_val_iter):\n","    \n","    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n","                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n","                                     monitor='val_loss', save_best_only=False, \\\n","                                     save_weights_only=True)\n","                     ]\n","    \n","    def train_gen():\n","        while True:\n","            train_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n","                             aspect, pretrain_X, pretrain_y in batch_train_iter]\n","            for train_batch in train_batches:\n","                yield train_batch\n","                \n","    def val_gen():\n","        while True:\n","            val_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n","                           aspect, pretrain_X, pretrain_y in batch_val_iter]\n","            for val_batch in val_batches:\n","                yield val_batch\n","                \n","    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n","                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n","                                  epochs = 10, callbacks = earlystop_callbacks)\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFyKY0ngvpDI","colab_type":"code","outputId":"3fffd185-541b-4255-882f-e2eae034b07b","executionInfo":{"status":"ok","timestamp":1589837772786,"user_tz":-120,"elapsed":897387,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":427}},"source":["train_generator(model, batch_train_iter, batch_val_iter)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","58/57 [==============================] - 92s 2s/step - loss: 1.0709 - aspect_model_loss: 0.9614 - pretrain_model_loss: 1.0949 - aspect_model_categorical_accuracy: 0.5673 - pretrain_model_categorical_accuracy: 0.3739 - val_loss: 0.9534 - val_aspect_model_loss: 0.8635 - val_pretrain_model_loss: 1.0677 - val_aspect_model_categorical_accuracy: 0.6313 - val_pretrain_model_categorical_accuracy: 0.4354\n","Epoch 2/10\n","58/57 [==============================] - 90s 2s/step - loss: 0.8093 - aspect_model_loss: 0.7064 - pretrain_model_loss: 1.0290 - aspect_model_categorical_accuracy: 0.7209 - pretrain_model_categorical_accuracy: 0.4844 - val_loss: 0.9283 - val_aspect_model_loss: 0.9174 - val_pretrain_model_loss: 0.9874 - val_aspect_model_categorical_accuracy: 0.5729 - val_pretrain_model_categorical_accuracy: 0.4750\n","Epoch 3/10\n","58/57 [==============================] - 89s 2s/step - loss: 0.6820 - aspect_model_loss: 0.5830 - pretrain_model_loss: 0.9892 - aspect_model_categorical_accuracy: 0.7796 - pretrain_model_categorical_accuracy: 0.5135 - val_loss: 0.9613 - val_aspect_model_loss: 0.9246 - val_pretrain_model_loss: 0.9434 - val_aspect_model_categorical_accuracy: 0.6417 - val_pretrain_model_categorical_accuracy: 0.5250\n","Epoch 4/10\n","58/57 [==============================] - 88s 2s/step - loss: 0.6227 - aspect_model_loss: 0.5264 - pretrain_model_loss: 0.9630 - aspect_model_categorical_accuracy: 0.8071 - pretrain_model_categorical_accuracy: 0.5129 - val_loss: 0.7555 - val_aspect_model_loss: 0.8967 - val_pretrain_model_loss: 0.9257 - val_aspect_model_categorical_accuracy: 0.6125 - val_pretrain_model_categorical_accuracy: 0.5312\n","Epoch 5/10\n","58/57 [==============================] - 88s 2s/step - loss: 0.5431 - aspect_model_loss: 0.4508 - pretrain_model_loss: 0.9226 - aspect_model_categorical_accuracy: 0.8384 - pretrain_model_categorical_accuracy: 0.5447 - val_loss: 1.4550 - val_aspect_model_loss: 1.0070 - val_pretrain_model_loss: 0.9708 - val_aspect_model_categorical_accuracy: 0.6583 - val_pretrain_model_categorical_accuracy: 0.5146\n","Epoch 6/10\n","58/57 [==============================] - 88s 2s/step - loss: 0.5238 - aspect_model_loss: 0.4312 - pretrain_model_loss: 0.9266 - aspect_model_categorical_accuracy: 0.8411 - pretrain_model_categorical_accuracy: 0.5356 - val_loss: 0.9513 - val_aspect_model_loss: 0.9396 - val_pretrain_model_loss: 0.8881 - val_aspect_model_categorical_accuracy: 0.6271 - val_pretrain_model_categorical_accuracy: 0.5583\n","Epoch 7/10\n","58/57 [==============================] - 89s 2s/step - loss: 0.4811 - aspect_model_loss: 0.3898 - pretrain_model_loss: 0.9127 - aspect_model_categorical_accuracy: 0.8534 - pretrain_model_categorical_accuracy: 0.5426 - val_loss: 1.2744 - val_aspect_model_loss: 0.9598 - val_pretrain_model_loss: 0.8824 - val_aspect_model_categorical_accuracy: 0.6292 - val_pretrain_model_categorical_accuracy: 0.5750\n","Epoch 8/10\n","58/57 [==============================] - 90s 2s/step - loss: 0.4638 - aspect_model_loss: 0.3737 - pretrain_model_loss: 0.9013 - aspect_model_categorical_accuracy: 0.8702 - pretrain_model_categorical_accuracy: 0.5539 - val_loss: 1.0791 - val_aspect_model_loss: 0.8765 - val_pretrain_model_loss: 0.8539 - val_aspect_model_categorical_accuracy: 0.6896 - val_pretrain_model_categorical_accuracy: 0.5771\n","Epoch 9/10\n","58/57 [==============================] - 90s 2s/step - loss: 0.4155 - aspect_model_loss: 0.3272 - pretrain_model_loss: 0.8825 - aspect_model_categorical_accuracy: 0.8836 - pretrain_model_categorical_accuracy: 0.5814 - val_loss: 1.3944 - val_aspect_model_loss: 1.0983 - val_pretrain_model_loss: 0.9142 - val_aspect_model_categorical_accuracy: 0.6396 - val_pretrain_model_categorical_accuracy: 0.5583\n","Epoch 10/10\n","58/57 [==============================] - 89s 2s/step - loss: 0.3952 - aspect_model_loss: 0.3075 - pretrain_model_loss: 0.8767 - aspect_model_categorical_accuracy: 0.8847 - pretrain_model_categorical_accuracy: 0.5593 - val_loss: 1.0744 - val_aspect_model_loss: 1.0457 - val_pretrain_model_loss: 0.8634 - val_aspect_model_categorical_accuracy: 0.6458 - val_pretrain_model_categorical_accuracy: 0.6000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aRm_R9Nd1RU9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzgT6fhq4xNZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}