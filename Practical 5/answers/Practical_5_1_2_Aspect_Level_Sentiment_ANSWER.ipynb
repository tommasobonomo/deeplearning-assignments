{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practical_5_1_2_Aspect_Level_Sentiment_ANSWER.ipynb","provenance":[],"collapsed_sections":["uaWk1GuHvpB1","-ZIcsq-SvpCF"]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ph91TE5lvthU","colab_type":"code","outputId":"428bd9aa-cb5d-452b-9691-6fadfd788b13","executionInfo":{"status":"ok","timestamp":1591392880019,"user_tz":-120,"elapsed":32348,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["from google.colab import drive\n","drive.mount('/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YoczuTvdhwQY","colab_type":"code","colab":{}},"source":["import keras.backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints\n","import tensorflow as tf\n","\n","\n","from keras.models import Model\n","from keras.layers import Input, Embedding, Dense, Lambda, Dropout, LSTM\n","from keras.layers import Reshape, Activation, RepeatVector, concatenate, Concatenate, Dot, Multiply"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7BivIvvvzaW","colab_type":"code","colab":{}},"source":["# You will need to change the following directory path according to your own path\n","#cd drive/My Drive/Recsys-2019/sequence_classifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P0VnIJhDRpvc","colab":{}},"source":["import os\n","import sys\n","import codecs\n","import operator\n","import numpy as np\n","import re\n","from time import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lM1cs7o-vpAW","colab_type":"code","colab":{}},"source":["import _pickle as cPickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UPslRReavpAZ","colab_type":"code","colab":{}},"source":["aspect_path = '/drive/My Drive/Deep Learing Course/practice-5-data/aspect_level-sentiment/aspect_level/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkm19_52vpAd","colab_type":"code","colab":{}},"source":["doc_path = '/drive/My Drive/Deep Learing Course/practice-5-data/doc_level-sentiment/doc_level/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gl50euzvDcQP","colab":{}},"source":["### Reading preprocess data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Sk_RKQSvpAj","colab_type":"code","colab":{}},"source":["def read_pickle(data_path, file_name):\n","\n","    f = open(os.path.join(data_path, file_name), 'rb')\n","    read_file = cPickle.load(f)\n","    f.close()\n","\n","    return read_file\n","\n","def save_pickle(data_path, file_name, data):\n","\n","    f = open(os.path.join(data_path, file_name), 'wb')\n","    cPickle.dump(data, f)\n","    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n","    f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwVGqOSavpAm","colab_type":"code","colab":{}},"source":["vocab = read_pickle(aspect_path, 'all_vocab.pkl')\n","\n","train_x = read_pickle(aspect_path, 'train_x.pkl')\n","train_y = read_pickle(aspect_path, 'train_y.pkl')\n","dev_x = read_pickle(aspect_path, 'dev_x.pkl')\n","dev_y = read_pickle(aspect_path, 'dev_y.pkl')\n","test_x = read_pickle(aspect_path, 'test_x.pkl')\n","test_y = read_pickle(aspect_path, 'test_y.pkl')\n","\n","train_aspect = read_pickle(aspect_path, 'train_aspect.pkl')\n","dev_aspect = read_pickle(aspect_path, 'dev_aspect.pkl')\n","test_aspect = read_pickle(aspect_path, 'test_aspect.pkl')\n","\n","\n","pretrain_data = read_pickle(aspect_path, 'pretrain_data.pkl')\n","pretrain_label = read_pickle(aspect_path, 'pretrain_label.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBmfsDKdvpAu","colab_type":"text"},"source":["### Batch generator and data iterator "]},{"cell_type":"code","metadata":{"id":"p_b-5_EPvpAv","colab_type":"code","colab":{}},"source":["class Dataiterator():\n","    '''\n","      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n","      2) Access to the entire dataset using all()\n","    '''\n","    \n","    def __init__(self, aspect_data, doc_data, seq_length=32, decoder_dim=300, batch_size=32):\n","        \n","        len_aspect_data = len(aspect_data[0])\n","        self.len_doc_data = len(doc_data[0])\n","        \n","        self.X_aspect = aspect_data[0] \n","        self.y_aspect = aspect_data[1]\n","        self.aspect_terms = aspect_data[2]\n","        \n","        self.X_doc = doc_data[0]\n","        self.y_doc = doc_data[1]\n","        \n","        self.num_data = len_aspect_data\n","        self.batch_size = batch_size # batch size\n","        self.reset() # initial: shuffling examples and set index to 0\n","    \n","    def __iter__(self): # iterates data\n","        return self\n","\n","\n","    def reset(self): # initials\n","        self.idx = 0\n","        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n","        \n","    def __next__(self): # return model inputs - outputs per batch\n","        \n","        X_ids = [] # hold ids per batch \n","        while len(X_ids) < self.batch_size:\n","            X_id = self.order[self.idx] # copy random id from initial shuffling\n","            X_ids.append(X_id)\n","            self.idx += 1 # \n","            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n","                self.reset()\n","                raise StopIteration()\n","                \n","        batch_X_aspect = self.X_aspect[np.array(X_ids)] # X values (encoder input) per batch\n","        batch_y_aspect = self.y_aspect[np.array(X_ids)] # y_in values (decoder input) per batch\n","        batch_aspect_terms = self.aspect_terms[np.array(X_ids)]\n","        indices_2 = np.random.choice(self.len_doc_data, self.batch_size)\n","        batch_X_doc = self.X_doc[indices_2]\n","        batch_y_doc = self.y_doc[indices_2]\n","        \n","        \n","        return batch_X_aspect, batch_y_aspect, batch_aspect_terms, batch_X_doc, batch_y_doc\n","\n","          \n","    def all(self): # return all data examples\n","        return self.X_aspect, self.y_aspect, self.aspect_terms, self.X_doc, self.y_doc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYHaDndlht2U","colab_type":"code","colab":{}},"source":["overal_maxlen = 82   # the max length for sentence \n","overal_maxlen_aspect = 7   # the max length for aspect terms"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Dnbn0_O0XlGf"},"source":["### Attention Network"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zjiAsayW1zx9","colab":{}},"source":["#self defined class: to calculate softmax\n","class Custom_softmax(Layer):\n","  \n","    def __init__(self, mask_zero=True, **kwargs):\n","        self.mask_zero = mask_zero\n","        self.supports_masking = True\n","        super(Custom_softmax, self).__init__(**kwargs)\n","\n","    def call(self, x,mask=None):\n","        if self.mask_zero:\n","            a = K.exp(x)         \n","            mask = K.cast(mask, K.floatx())  # mask for removing the influence of padded value\n","            mask = K.expand_dims(mask)\n","            a = a * mask\n","            a=a / (K.sum(a, axis=1, keepdims=True) + K.epsilon())\n","            return a\n","        else:\n","            return K.softmax(x, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[1],1)\n","    \n","    def compute_mask(self, x, mask):\n","        return None\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqjhBhMsaSeY","colab_type":"text"},"source":["###Attention function\n","$t$:query, the output of wordembedding from aspect term\n","\n","$h$:keys, the output sequence of LSTM from sentence\n","\n","$score(.)=v^T tanh(W[t;h])$\n","\n","$\\alpha=Softmax(score(.))$\n","\n","$context=\\sum{\\alpha h}$"]},{"cell_type":"code","metadata":{"id":"diZ0gfVIdGmD","colab_type":"code","colab":{}},"source":["#instantiate operators for attention network\n","repeator = RepeatVector(overal_maxlen, name='repeator_att')  # repeat tensors: [None, 1, Dimension-output-wordembedding]->[None,overal-maxlen,Dimension-output-wordembedding]\n","concatenator = Concatenate(axis=-1, name='concator_att')     #concate key and query [t;h]\n","densor1 = Dense(300, activation = \"tanh\", name='densor1_att') #  for the tanh(W[t;h])\n","densor2 = Dense(1, activation = \"relu\", name='densor2_att')   # for the mulplication of V_T and tanh(W[t;h])\n","activator = Custom_softmax(mask_zero=True,name='softmax_att') # for th softmax\n","dotor = Dot(axes = 1, name='dotor_att')                       #to do weighted sum of output sequence of LSTM based on attention weights \\alpha"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VH3g4z6R8O3_","colab":{}},"source":["########################################################################################################################################\n","#### Shape of Keys:[batch-size, overal-maxlen,Dimension_output_lstm], Shape of query: [batch-size,1,Dimension-output-wordEmbedding]  ###\n","########################################################################################################################################\n","def attention(keys, query):\n","    \n","    query = repeator(query)  #repeat aspect term to the over-maxlen\n","    print(\"query shape: %s\" %str(query._keras_shape))\n","    concat = concatenator([keys, query])   #to concate key and query [t;h]\n","    print(\"concat shape: %s\" %str(concat._keras_shape))\n","    e1 = densor1(concat)                   #tanh(W[t;h])\n","    print(\"e1 shape: %s\" %str(e1._keras_shape))\n","    e2 = densor2(e1)                       # to mulitply V_T and tanh(W[t;h])\n","    print(\"e2 shape: %s\" %str(e2._keras_shape))\n","    alphas = activator(e2)                 # softmax\n","    print(\"alphas shape: %s\" %str(alphas._keras_shape))\n","    context = dotor([alphas, keys])        #weighted sum\n","    print(\"context shape: %s\" %str(context._keras_shape))\n","    \n","    return context, alphas"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gVmvIn0X_0Ji","colab":{}},"source":["#self-defined class for averaging a tensor with axis=1\n","class Average(Layer):\n","  \n","    def __init__(self, mask_zero=True, **kwargs):\n","        self.mask_zero = mask_zero\n","        self.supports_masking = True\n","        super(Average, self).__init__(**kwargs)\n","\n","    def call(self, x,mask=None):\n","        if self.mask_zero:           \n","            mask = K.cast(mask, K.floatx())\n","            mask = K.expand_dims(mask)\n","            x = x * mask\n","            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n","        else:\n","            return K.mean(x, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[-1])\n","    \n","    def compute_mask(self, x, mask):\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TsyFHokczuvO"},"source":["# Create computation Graph"]},{"cell_type":"code","metadata":{"id":"pBdo6q2QvpBW","colab_type":"code","colab":{}},"source":["dropout = 0.5     \n","recurrent_dropout = 0.1\n","vocab_size = len(vocab)\n","num_outputs = 3 # labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xQVV-MRRvpBc","colab_type":"text"},"source":["### Define inputs"]},{"cell_type":"code","metadata":{"id":"eJ7tv-7GvpBd","colab_type":"code","colab":{}},"source":["#####create  Input tensor #####\n","sentence_input = Input(shape=(overal_maxlen,), dtype='int32', name='sentence_input')  #input for sentence from aspect-level data\n","aspect_input = Input(shape=(overal_maxlen_aspect,), dtype='int32', name='aspect_input') #input for aspect terms\n","pretrain_input = Input(shape=(None,), dtype='int32', name='pretrain_input')             #input for sentence from document-level data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58PLwihDvpBk","colab_type":"text"},"source":["### Wordembedding layers"]},{"cell_type":"code","metadata":{"id":"wJxzja4GvpBm","colab_type":"code","colab":{}},"source":["##### create word embedding layer #####\n","word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uaWk1GuHvpB1","colab_type":"text"},"source":["### Aspect-level representation (averaged)"]},{"cell_type":"code","metadata":{"id":"Q9q7v6TyvpB2","colab_type":"code","outputId":"26b1efdd-f644-48c2-d9d9-16257d6328fb","executionInfo":{"status":"ok","timestamp":1591395123197,"user_tz":-120,"elapsed":895,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["### represent aspect as averaged word embedding ###\n","print ('use average term embs as aspect embedding')\n","aspect_term_embs = word_emb(aspect_input)\n","aspect_embs = Average(mask_zero=True, name='aspect_emb')(aspect_term_embs)  #There could be mutiple words for aspect terms, here is to average the wordembedding of these aspect terms"],"execution_count":0,"outputs":[{"output_type":"stream","text":["use average term embs as aspect embedding\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ZIcsq-SvpCF","colab_type":"text"},"source":["### Sentence-level representation from two domains"]},{"cell_type":"code","metadata":{"id":"lRCN6JX4vpCH","colab_type":"code","colab":{}},"source":["### sentence representation ###\n","sentence_embs = word_emb(sentence_input) # from aspect-level domain\n","pretrain_embs = word_emb(pretrain_input) # from document-level domain"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6MzAALsZMrxM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7wvA7CahvpCL","colab_type":"text"},"source":["### LSTM layer (shared between three representations)"]},{"cell_type":"code","metadata":{"id":"FEJg_StjvpCN","colab_type":"code","colab":{}},"source":["rnn = LSTM(300, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout, name='lstm')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JpWf9bQvpCR","colab_type":"code","outputId":"790d2fe3-0a62-4e36-c0f8-404b86c92813","executionInfo":{"status":"ok","timestamp":1591395150639,"user_tz":-120,"elapsed":1219,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["### sentence representation ###\n","sentence_lstm = rnn(sentence_embs)    # from aspect-level domain\n","pretrain_lstm = rnn(pretrain_embs)     # from document-level domain\n","print(sentence_lstm.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(None, 82, 300)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fKL8d3asjQRf","colab_type":"text"},"source":["###attention layer"]},{"cell_type":"code","metadata":{"id":"LnYbFaqPvpCX","colab_type":"code","outputId":"216213bf-6b07-4ba3-fe82-8f9fbcc1ab99","executionInfo":{"status":"ok","timestamp":1591395150643,"user_tz":-120,"elapsed":983,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["att_context,att_weights=attention(sentence_lstm,aspect_embs)  #create atention layer: keys: output sequence of LSTM, query: the wordembedding of aspect term"],"execution_count":0,"outputs":[{"output_type":"stream","text":["query shape: (None, 82, 300)\n","concat shape: (None, 82, 600)\n","e1 shape: (None, 82, 300)\n","e2 shape: (None, 82, 1)\n","alphas shape: (None, 82, 1)\n","context shape: (None, 1, 300)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fkYgkg1-jS3R","colab_type":"text"},"source":["###prediction layer"]},{"cell_type":"code","metadata":{"id":"wmAFYpc5vpCa","colab_type":"code","colab":{}},"source":["#prediction layer\n","pretrain_avg = Average(mask_zero=True)(pretrain_lstm)\n","sentence_output = Dense(num_outputs, name='dense_1')(att_context)  #for aspect-level\n","pretrain_output = Dense(num_outputs, name='dense_2')(pretrain_avg)  # for document-level\n","sentence_output = Reshape((num_outputs,))(sentence_output)          # to squeeze the shape from (None,1,3) to (None,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T74EglluvpCh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_EmohJBvpCr","colab_type":"code","colab":{}},"source":["aspect_probs = Activation('softmax', name='aspect_model')(sentence_output)\n","doc_probs = Activation('softmax', name='pretrain_model')(pretrain_output)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ndmQ5-4ijcaY","colab_type":"text"},"source":["###build model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c6ptr7iuWIYT","colab":{}},"source":["model = Model(inputs=[sentence_input, aspect_input, pretrain_input], outputs=[aspect_probs, doc_probs])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bmPSF8IAENj_","colab":{}},"source":["import keras.optimizers as opt\n","\n","optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)  #define optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eiFkEy-eVtoU","outputId":"c480d0b9-0314-42a2-9c8d-0ca45c4842a2","executionInfo":{"status":"ok","timestamp":1591395460339,"user_tz":-120,"elapsed":881,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":888}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","sentence_input (InputLayer)     (None, 82)           0                                            \n","__________________________________________________________________________________________________\n","aspect_input (InputLayer)       (None, 7)            0                                            \n","__________________________________________________________________________________________________\n","word_emb (Embedding)            multiple             3000900     aspect_input[0][0]               \n","                                                                 sentence_input[0][0]             \n","                                                                 pretrain_input[0][0]             \n","__________________________________________________________________________________________________\n","aspect_emb (Average)            (None, 300)          0           word_emb[0][0]                   \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     multiple             721200      word_emb[1][0]                   \n","                                                                 word_emb[2][0]                   \n","__________________________________________________________________________________________________\n","repeator_att (RepeatVector)     (None, 82, 300)      0           aspect_emb[0][0]                 \n","__________________________________________________________________________________________________\n","concator_att (Concatenate)      (None, 82, 600)      0           lstm[0][0]                       \n","                                                                 repeator_att[0][0]               \n","__________________________________________________________________________________________________\n","densor1_att (Dense)             (None, 82, 300)      180300      concator_att[0][0]               \n","__________________________________________________________________________________________________\n","densor2_att (Dense)             (None, 82, 1)        301         densor1_att[0][0]                \n","__________________________________________________________________________________________________\n","pretrain_input (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","softmax_att (Custom_softmax)    (None, 82, 1)        0           densor2_att[0][0]                \n","__________________________________________________________________________________________________\n","dotor_att (Dot)                 (None, 1, 300)       0           softmax_att[0][0]                \n","                                                                 lstm[0][0]                       \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1, 3)         903         dotor_att[0][0]                  \n","__________________________________________________________________________________________________\n","average_6 (Average)             (None, 300)          0           lstm[1][0]                       \n","__________________________________________________________________________________________________\n","reshape_3 (Reshape)             (None, 3)            0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 3)            903         average_6[0][0]                  \n","__________________________________________________________________________________________________\n","aspect_model (Activation)       (None, 3)            0           reshape_3[0][0]                  \n","__________________________________________________________________________________________________\n","pretrain_model (Activation)     (None, 3)            0           dense_2[0][0]                    \n","==================================================================================================\n","Total params: 3,904,507\n","Trainable params: 3,904,507\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FaNcPdHiC650","colab":{}},"source":["model.compile(optimizer=optimizer,\n","              loss={'aspect_model': 'categorical_crossentropy', 'pretrain_model': 'categorical_crossentropy'},\n","              loss_weights = {'aspect_model': 1, 'pretrain_model': 0.1},\n","              metrics = {'aspect_model': 'categorical_accuracy', 'pretrain_model': 'categorical_accuracy'})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ilIKUGn_DEgB"},"source":["### Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Xi0coTFsDWFG","colab":{}},"source":["batch_size = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5Y3_eO4QgyC3","colab":{}},"source":["#for train set\n","train_steps_epoch = len(train_x)/batch_size  #define epoches\n","batch_train_iter = Dataiterator([train_x, train_y, train_aspect], \\\n","                                [pretrain_data, pretrain_label], batch_size)  # data iterator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NvFUoJlvpDA","colab_type":"code","colab":{}},"source":["#for validation set\n","val_steps_epoch = len(dev_x)/batch_size\n","batch_val_iter = Dataiterator([dev_x, dev_y, dev_aspect], \\\n","                              [pretrain_data, pretrain_label], batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vVb-obDevpDD","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","def train_generator(model, batch_train_iter, batch_val_iter):\n","    \n","    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n","                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n","                                     monitor='val_loss', save_best_only=False, \\\n","                                     save_weights_only=True)\n","                     ]\n","    \n","    def train_gen():\n","        while True:\n","            train_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n","                             aspect, pretrain_X, pretrain_y in batch_train_iter]\n","            for train_batch in train_batches:\n","                yield train_batch\n","                \n","    def val_gen():\n","        while True:\n","            val_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n","                           aspect, pretrain_X, pretrain_y in batch_val_iter]\n","            for val_batch in val_batches:\n","                yield val_batch\n","                \n","    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n","                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n","                                  epochs = 10, callbacks = earlystop_callbacks)\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFyKY0ngvpDI","colab_type":"code","outputId":"4f34e7d3-7ba2-4a1d-9b3e-258a7e0b2b0c","executionInfo":{"status":"error","timestamp":1591395488209,"user_tz":-120,"elapsed":22508,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":407}},"source":["train_generator(model, batch_train_iter, batch_val_iter)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","15/57 [======>.......................] - ETA: 51s - loss: 1.1741 - aspect_model_loss: 1.0638 - pretrain_model_loss: 1.1035 - aspect_model_categorical_accuracy: 0.4896 - pretrain_model_categorical_accuracy: 0.3479"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-95-8128b7813175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_train_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_val_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-94-d15e4dfcc672>\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(model, batch_train_iter, batch_val_iter)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mval_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps_epoch\u001b[0m\u001b[0;34m,\u001b[0m                                   \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearlystop_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"aRm_R9Nd1RU9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}