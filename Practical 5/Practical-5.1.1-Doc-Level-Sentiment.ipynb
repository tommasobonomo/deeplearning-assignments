{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Practical-5.1.1-Doc-Level-Sentiment.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"FlLAfx6lqYeu","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import codecs\n","import operator\n","import numpy as np\n","import re\n","from time import time\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4J_ekjkvAxFI","colab_type":"code","outputId":"6247b5d4-3dfb-417e-e19b-d3e8f1a65e7e","executionInfo":{"status":"ok","timestamp":1589614213373,"user_tz":-120,"elapsed":2570,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow\n","from tensorflow import keras\n","print(tensorflow.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N5MJJO2wnwoP","colab_type":"code","outputId":"4baa245e-fa47-4e42-bd4b-323b89163d42","executionInfo":{"status":"ok","timestamp":1589614243675,"user_tz":-120,"elapsed":29806,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c4a7cjbZqYe3","colab_type":"code","colab":{}},"source":["import _pickle as cPickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-1eyJ-uqYe8","colab_type":"code","colab":{}},"source":["data_path = '/drive/My Drive/Deep Learing Course/practice-5-data/doc_level-sentiment/doc_level/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tttZAPSHqYfB","colab_type":"text"},"source":["### Reading preprocess data"]},{"cell_type":"code","metadata":{"id":"od-Wq3ENqYfC","colab_type":"code","colab":{}},"source":["def read_pickle(data_path, file_name):\n","\n","    f = open(os.path.join(data_path, file_name), 'rb')\n","    read_file = cPickle.load(f)\n","    f.close()\n","\n","    return read_file\n","\n","def save_pickle(data_path, file_name, data):\n","\n","    f = open(os.path.join(data_path, file_name), 'wb')\n","    cPickle.dump(data, f)\n","    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n","    f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vVhPTijBqYfH","colab_type":"code","colab":{}},"source":["words_idx = read_pickle(data_path, 'words_idx.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JohE4cOZqYfR","colab_type":"code","colab":{}},"source":["idx_words = read_pickle(data_path, 'idx_words.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJm9O5XqqYfX","colab_type":"code","colab":{}},"source":["data = read_pickle(data_path, 'data.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXiaLnIhqYff","colab_type":"code","colab":{}},"source":["label = read_pickle(data_path, 'label.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mz5ekJHGqYfj","colab_type":"text"},"source":["### Preparing training and validation set"]},{"cell_type":"code","metadata":{"id":"RQOjDKlBqYfk","colab_type":"code","outputId":"a08464eb-1ecb-45d7-904e-35951a683e6b","executionInfo":{"status":"ok","timestamp":1589614255507,"user_tz":-120,"elapsed":3956,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.preprocessing import sequence\n","from keras.utils.np_utils import to_categorical\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FKqtZaMoqYfo","colab_type":"code","colab":{}},"source":["rand_idx = np.arange(len(data))\n","np.random.shuffle(rand_idx)\n","\n","data = data[rand_idx]\n","label = to_categorical(label)[rand_idx]\n","\n","data_size = len(data)\n","\n","test_x = data[0:1000]\n","test_y = label[0:1000]\n","\n","dev_x = data[1000:5000]\n","dev_y = label[1000:5000]\n","\n","train_x = data[5000:int(data_size)]\n","train_y = label[5000:int(data_size)]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CW1TfwOTqYfs","colab_type":"code","colab":{}},"source":["maxlen = np.max([len(d) for d in data])\n","\n","#import operator\n","#words_idx = [x for (x, _) in sorted(words_idx.items(), key=operator.itemgetter(1))]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJDcDkF8qYf2","colab_type":"code","colab":{}},"source":["train_x_ = sequence.pad_sequences(train_x, maxlen)\n","dev_x_ = sequence.pad_sequences(dev_x, maxlen)\n","test_x_ = sequence.pad_sequences(test_x, maxlen)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldDSx3jEqYf7","colab_type":"code","colab":{}},"source":["train_x_ = np.array(train_x_)\n","train_y = np.array(train_y)\n","\n","dev_x_ = np.array(dev_x_)\n","dev_y = np.array(dev_y)\n","\n","test_x_ = np.array(test_x_)\n","test_y = np.array(test_y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HkGYRHRtqYf_","colab_type":"text"},"source":["### Data iterator"]},{"cell_type":"code","metadata":{"id":"NGfY4bsJqYgA","colab_type":"code","colab":{}},"source":["class Dataiterator():\n","    '''\n","      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n","      2) Access to the entire dataset using all()\n","    '''\n","    \n","    def __init__(self, X, y, seq_length=32, decoder_dim=300, batch_size=32):      \n","        self.X = X \n","        self.y = y \n","        self.num_data = len(X) # total number of examples\n","        self.batch_size = batch_size # batch size\n","        self.reset() # initial: shuffling examples and set index to 0\n","    \n","    def __iter__(self): # iterates data\n","        return self\n","\n","\n","    def reset(self): # initials\n","        self.idx = 0\n","        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n","        \n","    def __next__(self): # return model inputs - outputs per batch\n","        X_ids = [] # hold ids per batch \n","        while len(X_ids) < self.batch_size:\n","            X_id = self.order[self.idx] # copy random id from initial shuffling\n","            X_ids.append(X_id)\n","            self.idx += 1 # \n","            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n","                self.reset()\n","                raise StopIteration()\n","                \n","        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n","        batch_y = self.y[np.array(X_ids)] # y_in values (decoder input) per batch\n","        return batch_X, batch_y\n","\n","          \n","    def all(self): # return all data examples\n","        return self.X, self.y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbFp3Vp5qYgD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"13GNLSaWu7np"},"source":["### LSTM Model for document level sentiment classification"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p0I4Ob1uvL3O","colab":{}},"source":["from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Input\n","from keras.models import Model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rw97leGHqYgU","colab_type":"text"},"source":["### Input Layer"]},{"cell_type":"code","metadata":{"id":"-DudAolfqYgU","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M97ywPilqYga","colab_type":"text"},"source":["### Layer to train embedding weights of words"]},{"cell_type":"code","metadata":{"id":"zoOZ_aeqqYga","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oieFIAJkqYgg","colab_type":"text"},"source":["### RNN-based layer "]},{"cell_type":"code","metadata":{"id":"iiktDAQFqYgg","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MMXD4dJEqYgk","colab_type":"text"},"source":["### Prediction layer"]},{"cell_type":"code","metadata":{"id":"93Cb-P2VqYgk","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkgSIsouqYgo","colab_type":"text"},"source":["### Construct the model"]},{"cell_type":"code","metadata":{"id":"1hJ0QkkOqYgo","colab_type":"code","colab":{}},"source":["### YOUR CODE HERE\n","\n","model = "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UAaC4TwKvVrF","colab":{}},"source":["import keras.optimizers as opt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RaKx1llGv0Zp","colab":{}},"source":["optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yUv6dojGv5ZR","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zNk6R3meqYg9","colab_type":"text"},"source":["### Training with batch generator"]},{"cell_type":"code","metadata":{"id":"4z9mFsH0qYg-","colab_type":"code","colab":{}},"source":["batch_size = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H_apU4dZyFYE","colab":{}},"source":["train_steps_epoch = len(train_x_)/batch_size\n","batch_train_iter = Dataiterator(train_x_, train_y, batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D7IPM9JkqYhF","colab_type":"code","colab":{}},"source":["val_steps_epoch = len(dev_x_)/batch_size\n","batch_val_iter = Dataiterator(dev_x_, dev_y, batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkyKccPZqYhL","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","def train_generator(model, batch_train_iter, batch_val_iter):\n","    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n","                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n","                                     monitor='val_loss', save_best_only=False, \\\n","                                     save_weights_only=True)\n","                     ]\n","    \n","    def train_gen():\n","        while True:\n","            train_batches = [[X, y] for X, y in batch_train_iter]\n","            for train_batch in train_batches:\n","                yield train_batch\n","                \n","    def val_gen():\n","        while True:\n","            val_batches = [[X, y] for X, y in batch_val_iter]\n","            for val_batch in val_batches:\n","                yield val_batch\n","                \n","    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n","                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n","                                  epochs = 20, callbacks = earlystop_callbacks)\n","    return history\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_MGHz45qYhP","colab_type":"code","colab":{}},"source":["history=train_generator(model, batch_train_iter, batch_val_iter)"],"execution_count":0,"outputs":[]}]}