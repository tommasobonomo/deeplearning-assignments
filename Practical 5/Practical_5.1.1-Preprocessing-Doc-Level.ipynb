{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Practical_5.1.1-Preprocessing-Doc-Level.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"eTvH9Q5vygvV","colab":{}},"source":["import os\n","import sys\n","import codecs\n","import operator\n","import numpy as np\n","import re\n","from time import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgSn_3jgHlEg","colab_type":"code","outputId":"2c60b354-421b-46e1-ce8f-ac3625d5a8d5","executionInfo":{"status":"ok","timestamp":1589557292598,"user_tz":-120,"elapsed":2513,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MvvZckO6qiZv","colab_type":"code","colab":{}},"source":["#data_path = 'data/doc_level-sentiment/doc_level'\n","data_path=r\"/drive/My Drive/Deep Learing Course/practice-5-data/doc_level-sentiment/doc_level/\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"73rQErIeqiZz","colab_type":"text"},"source":["## Vocabulary Indexing"]},{"cell_type":"markdown","metadata":{"id":"PcfZRr41qiZ0","colab_type":"text"},"source":["### Note: \n","\n","Pay attention how you represent your sequences as an input of RNN/LSTM model.\n","With a fixed length vector, you will need to pad the shorter sequences with \"0\".\n","Consequently, your vocabulary indexing needs to consider this \"0\" as padding."]},{"cell_type":"markdown","metadata":{"id":"1JyspKfpqiZ3","colab_type":"text"},"source":["### Function to create vocabulary index"]},{"cell_type":"markdown","metadata":{"id":"rE9FAE8dqiZ5","colab_type":"text"},"source":["### Returns:\n","\n","Python dictionary format of vocabulary indexing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hhiEyxIRm_HK","colab":{}},"source":["num_regex = re.compile('^[+-]?[0-9]+\\.?[0-9]*$')\n","\n","def create_vocab(domain, data_path, maxlen=0, vocab_size=0):\n","    \n","    print('Creating vocab ...')\n","\n","    f = os.path.join(data_path,'%s_text.txt'%(domain))\n","\n","    total_words, unique_words = 0, 0\n","    word_freqs = {}\n","\n","    fin = codecs.open(f, 'r', 'utf-8')\n","    for line in fin:\n","        words = line.split()\n","        if maxlen > 0 and len(words) > maxlen:\n","            continue\n","\n","        for w in words:\n","            if not bool(num_regex.match(w)):\n","                try:\n","                    word_freqs[w] += 1\n","                except KeyError:\n","                    unique_words += 1\n","                    word_freqs[w] = 1\n","                total_words += 1\n","\n","    print ('  %i total words, %i unique words' % (total_words, unique_words))\n","    sorted_word_freqs = sorted(word_freqs.items(), key=operator.itemgetter(1), reverse=True)\n","\n","    vocab = {'<pad>':0, '<unk>':1, '<num>':2}\n","    index = len(vocab)\n","    for word, _ in sorted_word_freqs:\n","        vocab[word] = index\n","        index += 1\n","        if vocab_size > 0 and index > vocab_size + 2:\n","            break\n","    if vocab_size > 0:\n","        print (' keep the top %i words' % vocab_size)\n","\n","  \n","    return vocab"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sPl_pYqKqiZ-","colab_type":"text"},"source":["## Sequence preprocessing"]},{"cell_type":"markdown","metadata":{"id":"i1RV6RrwqiaA","colab_type":"text"},"source":["### Function to transform word sequence -> integer sequence"]},{"cell_type":"markdown","metadata":{"id":"jwwOouMdqiaB","colab_type":"text"},"source":["### Note:\n","\n","The raw data set has 5 class labels. Here, we only consider 3 sentiment classes."]},{"cell_type":"markdown","metadata":{"id":"cDfUXTSFqiaB","colab_type":"text"},"source":["### Returns:\n","\n","integer sequence of text, corresponding labels (int), maxlen (maximum length of sequences)"]},{"cell_type":"code","metadata":{"id":"AyCpvNGWqiaC","colab_type":"code","colab":{}},"source":["def create_data(vocab, text_path, label_path, domain, skip_top, skip_len, replace_non_vocab):\n","    \n","    data = []\n","    label = [] # {pos: 0, neg: 1, neu: 2}\n","    \n","    f = codecs.open(text_path, 'r', 'utf-8')\n","    f_l = codecs.open(label_path, 'r', 'utf-8')\n","    \n","    num_hit, unk_hit, skip_top_hit, total = 0., 0., 0., 0.\n","    pos_count, neg_count, neu_count = 0, 0, 0\n","    max_len = 0\n","\n","    for line, score in zip(f, f_l):\n","        word_indices = []\n","        words = line.split()\n","        if skip_len > 0 and len(words) > skip_len:\n","            continue\n","\n","        score = float(score.strip())\n","        if score < 3:\n","            neg_count += 1\n","            label.append(1)\n","        elif score > 3:\n","            pos_count += 1\n","            label.append(0)\n","        else:\n","            neu_count += 1\n","            label.append(2)\n","          \n","        for word in words:\n","            if bool(num_regex.match(word)):\n","                word_indices.append(vocab['<num>'])\n","                num_hit += 1\n","            elif word in vocab:\n","                word_ind = vocab[word]\n","                if skip_top > 0 and word_ind < skip_top + 3:\n","                    skip_top_hit += 1\n","                else:\n","                    word_indices.append(word_ind)\n","            else:\n","                if replace_non_vocab:\n","                    word_indices.append(vocab['<unk>'])\n","                unk_hit += 1\n","            total += 1\n","\n","        if len(word_indices) > max_len:\n","            max_len = len(word_indices)\n","\n","        data.append(word_indices)\n","\n","    f.close()\n","    f_l.close()\n","\n","    print('  <num> hit rate: %.2f%%, <unk> hit rate: %.2f%%' % (100*num_hit/total, 100*unk_hit/total))\n","\n","    print (domain)\n","    print( 'pos count: ', pos_count )\n","    print( 'neg count: ', neg_count )\n","    print( 'neu count: ', neu_count )\n","\n","    return np.array(data), np.array(label), max_len\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-8h5_84qiaH","colab_type":"text"},"source":["### Main Preprocessing Function"]},{"cell_type":"markdown","metadata":{"id":"oNZRgjlnqiaI","colab_type":"text"},"source":["### Call : \n","\n","- create_vocab()\n","- create_data()"]},{"cell_type":"markdown","metadata":{"id":"9SAl42rnqiaJ","colab_type":"text"},"source":["### Return\n","\n","- vocabulary index\n","- integer sequence (model input)\n","- label (model output)\n","- maximum sequence length -> as parameter for RNN / LSTM"]},{"cell_type":"code","metadata":{"id":"WrMxVneLqiaL","colab_type":"code","colab":{}},"source":["def prepare_data(domain, data_path, vocab_size, skip_top=0, skip_len=0, replace_non_vocab=1):\n","    \n","    print(domain)\n","\n","    assert domain in ['amazon_electronics', 'yelp14']\n","\n","    vocab = create_vocab(domain, data_path, skip_len, vocab_size)\n","\n","    text_path = os.path.join(data_path,'%s_text.txt'%(domain))\n","    score_path = os.path.join(data_path,'%s_label.txt'%(domain))\n","\n","    data, label, max_len = create_data(vocab, text_path, score_path, domain, skip_top, \\\n","                                       skip_len, replace_non_vocab)\n","\n","    return vocab, data, label, max_len"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"agernQtwqiaS","colab_type":"text"},"source":["## Run Preprocessing"]},{"cell_type":"code","metadata":{"id":"g8lH2JG6qiaT","colab_type":"code","colab":{}},"source":["# choose domain data to train\n","domain_name = 'amazon_electronics'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cp_MkulGr5RZ","outputId":"c1b6f95a-ae5f-4ac3-f0fc-23b37833c2c3","executionInfo":{"status":"ok","timestamp":1589557305580,"user_tz":-120,"elapsed":8063,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":176}},"source":["vocab, data_list, label_list, overall_maxlen = prepare_data(domain_name, data_path, 10000)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["amazon_electronics\n","Creating vocab ...\n","  3440972 total words, 39122 unique words\n"," keep the top 10000 words\n","  <num> hit rate: 1.04%, <unk> hit rate: 1.56%\n","amazon_electronics\n","pos count:  10000\n","neg count:  10000\n","neu count:  10000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vBBYFahTqiac","colab_type":"code","outputId":"cdd458a7-b76e-4c68-9030-7c21de6ae2f3","executionInfo":{"status":"ok","timestamp":1589557305582,"user_tz":-120,"elapsed":7517,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["overall_maxlen"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1016"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"hRfvfzWcqiaj","colab_type":"code","outputId":"cc828a06-2ec5-4a29-d550-13d34772415b","executionInfo":{"status":"ok","timestamp":1589557305583,"user_tz":-120,"elapsed":6981,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data_list.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(30000,)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"5S-QTT06qiap","colab_type":"code","outputId":"4f478dc2-fb31-4401-fa14-2ad57e8ade39","executionInfo":{"status":"ok","timestamp":1589557305585,"user_tz":-120,"elapsed":6229,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(data_list[2]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["846\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F0PFlBsCqiau","colab_type":"code","outputId":"606c1617-781b-417f-a973-a10090da4e3c","executionInfo":{"status":"ok","timestamp":1589366229790,"user_tz":-120,"elapsed":705,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["label_list.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(30000,)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"ySlV5abBqiay","colab_type":"code","outputId":"9b92e414-46cf-4a93-ca1c-7115eec77530","executionInfo":{"status":"ok","timestamp":1589366241319,"user_tz":-120,"elapsed":713,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(label_list[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4qqkUcxYqia3","colab_type":"text"},"source":["### Example of how to access the stored vocabulary indexing"]},{"cell_type":"code","metadata":{"id":"rl8SR3caqia4","colab_type":"code","outputId":"3ba132c8-2854-4999-e2ef-1c81424f4f3e","executionInfo":{"status":"ok","timestamp":1589366245693,"user_tz":-120,"elapsed":723,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(list(vocab.items())[:5])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('<pad>', 0), ('<unk>', 1), ('<num>', 2), ('the', 3), ('i', 4)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2DdYhOqqqia8","colab_type":"code","outputId":"08dc5189-4b3b-49c3-b202-18c42a0f1b9f","executionInfo":{"status":"ok","timestamp":1589366251384,"user_tz":-120,"elapsed":817,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["vocab['love']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["301"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VkAMTb8lt0Xs","colab":{}},"source":["idx_words = dict((v,k) for (k,v) in vocab.items())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYNxAXSLqibF","colab_type":"code","outputId":"6518f130-058a-4b80-f348-6815d686d0ca","executionInfo":{"status":"ok","timestamp":1589366254834,"user_tz":-120,"elapsed":692,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(list(idx_words.items())[:5])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[(0, '<pad>'), (1, '<unk>'), (2, '<num>'), (3, 'the'), (4, 'i')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0iQ7hsShqibK","colab_type":"text"},"source":["### Storing all preprocessing data\n","\n","Here, we store as a pickle format"]},{"cell_type":"code","metadata":{"id":"i2V0aKECqibM","colab_type":"code","colab":{}},"source":["import _pickle as cPickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"73zvvPc1qibP","colab_type":"code","colab":{}},"source":["def read_pickle(data_path, file_name):\n","\n","    f = open(os.path.join(data_path, file_name), 'rb')\n","    read_file = cPickle.load(f)\n","    f.close()\n","\n","    return read_file\n","\n","def save_pickle(data_path, file_name, data):\n","\n","    f = open(os.path.join(data_path, file_name), 'wb')\n","    cPickle.dump(data, f)\n","    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n","    f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWWj25zzqibT","colab_type":"code","outputId":"5ef194b4-f373-478b-b7f0-ee4266727e7e","executionInfo":{"status":"ok","timestamp":1589366265391,"user_tz":-120,"elapsed":1191,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["save_pickle(data_path, 'words_idx.pkl', vocab)"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" file saved to: /drive/My Drive/Deep Learing Course/practice-5-data/doc_level-sentiment/doc_level/words_idx.pkl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2lCetoYXqibW","colab_type":"code","outputId":"1fda6339-c3fb-46e0-81f6-51061569c144","executionInfo":{"status":"ok","timestamp":1589366267825,"user_tz":-120,"elapsed":1559,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["save_pickle(data_path, 'idx_words.pkl', idx_words)"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" file saved to: /drive/My Drive/Deep Learing Course/practice-5-data/doc_level-sentiment/doc_level/idx_words.pkl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qzxlb-unqiba","colab_type":"code","outputId":"7354d744-4a0c-4d1e-b028-19980e99d767","executionInfo":{"status":"ok","timestamp":1589366273183,"user_tz":-120,"elapsed":2256,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["save_pickle(data_path, 'data.pkl', data_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" file saved to: /drive/My Drive/Deep Learing Course/practice-5-data/doc_level-sentiment/doc_level/data.pkl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z31Ki0vHqibh","colab_type":"code","outputId":"fd118dd0-7541-4c6a-c7e6-55394c8906d4","executionInfo":{"status":"ok","timestamp":1589366275915,"user_tz":-120,"elapsed":1369,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["save_pickle(data_path, 'label.pkl', label_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" file saved to: /drive/My Drive/Deep Learing Course/practice-5-data/doc_level-sentiment/doc_level/label.pkl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AzAngZZXnLkR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}