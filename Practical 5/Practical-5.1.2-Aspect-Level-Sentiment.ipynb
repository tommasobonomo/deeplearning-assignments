{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Practical-5.1.2-Aspect-Level-Sentiment.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"P0VnIJhDRpvc","colab":{}},"source":["import os\n","import sys\n","import codecs\n","import operator\n","import numpy as np\n","import re\n","from time import time\n","from tensorflow import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KD5kpfgB1o_z","colab_type":"code","outputId":"48d05a82-a482-4935-891b-dca5e271e6b3","executionInfo":{"status":"ok","timestamp":1589893936395,"user_tz":-120,"elapsed":32945,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EJ7e_DyF7ka-","colab_type":"code","colab":{}},"source":["import _pickle as cPickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4V9hW-r7kbF","colab_type":"code","colab":{}},"source":["aspect_path = '/drive/My Drive/Deep Learing Course/practice-5-data/aspect_level-sentiment/aspect_level/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gl50euzvDcQP","colab":{}},"source":["### Reading preprocess data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6rbh26b7kbe","colab_type":"code","colab":{}},"source":["def read_pickle(data_path, file_name):\n","\n","    f = open(os.path.join(data_path, file_name), 'rb')\n","    read_file = cPickle.load(f)\n","    f.close()\n","\n","    return read_file\n","\n","def save_pickle(data_path, file_name, data):\n","\n","    f = open(os.path.join(data_path, file_name), 'wb')\n","    cPickle.dump(data, f)\n","    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n","    f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uj5mi_qW7kbj","colab_type":"code","colab":{}},"source":["vocab = read_pickle(aspect_path, 'all_vocab.pkl')\n","\n","train_x = read_pickle(aspect_path, 'train_x.pkl')\n","train_y = read_pickle(aspect_path, 'train_y.pkl')\n","dev_x = read_pickle(aspect_path, 'dev_x.pkl')\n","dev_y = read_pickle(aspect_path, 'dev_y.pkl')\n","test_x = read_pickle(aspect_path, 'test_x.pkl')\n","test_y = read_pickle(aspect_path, 'test_y.pkl')\n","\n","train_aspect = read_pickle(aspect_path, 'train_aspect.pkl')\n","dev_aspect = read_pickle(aspect_path, 'dev_aspect.pkl')\n","test_aspect = read_pickle(aspect_path, 'test_aspect.pkl')\n","\n","\n","pretrain_data = read_pickle(aspect_path, 'pretrain_data.pkl')\n","pretrain_label = read_pickle(aspect_path, 'pretrain_label.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"adNP5FHo7kbr","colab_type":"text"},"source":["### Batch generator and data iterator "]},{"cell_type":"code","metadata":{"id":"m6PrfXAb7kbt","colab_type":"code","colab":{}},"source":["class Dataiterator():\n","    '''\n","      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n","      2) Access to the entire dataset using all()\n","    '''\n","    \n","    def __init__(self, aspect_data, doc_data, seq_length=32, decoder_dim=300, batch_size=32):\n","        \n","        len_aspect_data = len(aspect_data[0])\n","        len_doc_data = len(doc_data[0])\n","        \n","        self.X_aspect = aspect_data[0] \n","        self.y_aspect = aspect_data[1]\n","        self.aspect_terms = aspect_data[2]\n","        \n","        self.X_doc = doc_data[0]\n","        self.y_doc = doc_data[1]\n","        \n","        self.num_data = len_aspect_data\n","        self.batch_size = batch_size # batch size\n","        self.reset() # initial: shuffling examples and set index to 0\n","    \n","    def __iter__(self): # iterates data\n","        return self\n","\n","\n","    def reset(self): # initials\n","        self.idx = 0\n","        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n","        \n","    def __next__(self): # return model inputs - outputs per batch\n","        \n","        X_ids = [] # hold ids per batch \n","        while len(X_ids) < self.batch_size:\n","            X_id = self.order[self.idx] # copy random id from initial shuffling\n","            X_ids.append(X_id)\n","            self.idx += 1 # \n","            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n","                self.reset()\n","                raise StopIteration()\n","                \n","        batch_X_aspect = self.X_aspect[np.array(X_ids)] # X values (encoder input) per batch\n","        batch_y_aspect = self.y_aspect[np.array(X_ids)] # y_in values (decoder input) per batch\n","        batch_aspect_terms = self.aspect_terms[np.array(X_ids)]\n","        batch_X_doc = self.X_doc[np.array(X_ids)]\n","        batch_y_doc = self.y_doc[np.array(X_ids)]\n","        \n","        \n","        return batch_X_aspect, batch_y_aspect, batch_aspect_terms, batch_X_doc, batch_y_doc\n","\n","          \n","    def all(self): # return all data examples\n","        return self.X_aspect, self.y_aspect, self.aspect_terms, self.X_doc, self.y_doc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sklA6jSUWDS6"},"source":["### Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vDU0hXVJ1PR5","outputId":"3cdcd784-7aa1-49c0-9a2e-534745469769","executionInfo":{"status":"ok","timestamp":1589873378907,"user_tz":-120,"elapsed":9411,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.models import Model\n","from keras.layers import Input, Embedding, Dense, Lambda, Dropout, LSTM\n","from keras.layers import Reshape, Activation, RepeatVector, concatenate, Concatenate, Dot, Multiply"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pvg-Uf2h_6Qm","colab":{}},"source":["import keras.backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers\n","from keras import regularizers\n","from keras import constraints"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sCaGBEci1EA3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Dnbn0_O0XlGf"},"source":["### Attention Network"]},{"cell_type":"code","metadata":{"id":"YfwhzqK97kb9","colab_type":"code","colab":{}},"source":["overal_maxlen = 82\n","overal_maxlen_aspect = 7"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zjiAsayW1zx9","colab":{}},"source":["class Custom_softmax(Layer):\n","  \n","    def __init__(self, mask_zero=True, **kwargs):\n","        self.mask_zero = mask_zero\n","        self.supports_masking = True\n","        super(Custom_softmax, self).__init__(**kwargs)\n","\n","    def call(self, x,mask=None):\n","        if self.mask_zero:\n","            a = K.exp(x)         \n","            mask = K.cast(mask, K.floatx())\n","            mask = K.expand_dims(mask)\n","            a = a * mask\n","            a=a / (K.sum(a, axis=1, keepdims=True) + K.epsilon())\n","            return a\n","        else:\n","            return K.softmax(x, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[1],1)\n","    \n","    def compute_mask(self, x, mask):\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Bp5xh27GXmva","colab":{}},"source":["repeator = RepeatVector(overal_maxlen, name='repeator_att')\n","concatenator = Concatenate(axis=-1, name='concator_att')\n","densor1 = Dense(300, activation = \"tanh\", name='densor1_att')\n","densor2 = Dense(1, activation = \"relu\", name='densor2_att')\n","activator = Custom_softmax(mask_zero=True,name='softmax_att')\n","dotor = Dot(axes = 1, name='dotor_att')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vVz3DuBbU0yG","colab_type":"text"},"source":["keys shape:(batch_size,overal_maxlen,out_len_lstm)\n","Query shape:(batch_size,out_len_embedding)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VH3g4z6R8O3_","colab":{}},"source":["########################################################################################################################################\n","#### Shape of Keys:[batch-size, overal-maxlen,Dimension_output_lstm], Shape of query: [batch-size,1,Dimension-output-wordEmbedding]  ###\n","########################################################################################################################################\n","def attention(keys, query):\n","    query = repeator(query)\n","    print(\"query shape: %s\" %str(query._keras_shape))\n","    concat = concatenator([keys, query])\n","    print(\"concat shape: %s\" %str(concat._keras_shape))\n","    e1 = densor1(concat)\n","    print(\"e1 shape: %s\" %str(e1._keras_shape))\n","    e2 = densor2(e1)\n","    print(\"e2 shape: %s\" %str(e2._keras_shape))\n","    alphas = activator(e2)\n","    print(\"alphas shape: %s\" %str(alphas._keras_shape))\n","    context = dotor([alphas, keys])\n","    print(\"context shape: %s\" %str(context._keras_shape))\n","    \n","    return context, alphas"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gVmvIn0X_0Ji","colab":{}},"source":["class Average(Layer):\n","  \n","    def __init__(self, mask_zero=True, **kwargs):\n","        self.mask_zero = mask_zero\n","        self.supports_masking = True\n","        super(Average, self).__init__(**kwargs)\n","\n","    def call(self, x, mask=None):\n","        if self.mask_zero:\n","            mask = K.cast(mask, K.floatx())\n","            mask = K.expand_dims(mask)\n","            x = x * mask\n","            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n","        else:\n","            return K.mean(x, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[-1])\n","    \n","    def compute_mask(self, x, mask):\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TsyFHokczuvO"},"source":["### Main model"]},{"cell_type":"code","metadata":{"id":"zpjtVz0g7kcf","colab_type":"code","colab":{}},"source":["dropout = 0.5     \n","recurrent_dropout = 0.1\n","vocab_size = len(vocab)\n","num_outputs = 3 # labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kvUi2LZu7kcj","colab_type":"text"},"source":["### Inputs: How many inputs do you need for the current task?"]},{"cell_type":"code","metadata":{"id":"n--aInYI7kck","colab_type":"code","colab":{}},"source":["##### Inputs #####\n","sentence_input = Input(shape=(overal_maxlen,), dtype='int32', name='sentence_input')\n","aspect_input = Input(shape=(overal_maxlen_aspect,), dtype='int32', name='aspect_input')\n","pretrain_input = Input(shape=(None,), dtype='int32', name='pretrain_input')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMS-elf-x4UU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tAj0NHwX7kcr","colab_type":"text"},"source":["### Word-level embedding (shareable between all model inputs)"]},{"cell_type":"code","metadata":{"id":"Xktj5dB77kcs","colab_type":"code","colab":{}},"source":["##### construct word embedding layer #####\n","word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9DoLxX_f7kcw","colab_type":"text"},"source":["### Aspect-level representation (averaged)"]},{"cell_type":"code","metadata":{"id":"ULXduGya7kcx","colab_type":"code","outputId":"7fa0a202-8768-4d6b-a9a7-e95ee0274dd1","executionInfo":{"status":"ok","timestamp":1589837918719,"user_tz":-120,"elapsed":662,"user":{"displayName":"tianjin huang","photoUrl":"","userId":"00543616640831635256"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["### represent aspect as averaged word embedding ###\n","print ('use average term embs as aspect embedding')\n","                                                   #get the embedding representation for asepct terms\n","                                                   # average it Using Average  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["use average term embs as aspect embedding\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4DpH3jWF7kc6","colab_type":"text"},"source":["### Sentence-level representation from two domains"]},{"cell_type":"code","metadata":{"id":"QXNovw_A7kc8","colab_type":"code","colab":{}},"source":["### sentence representation ###\n","sentence_embs=                                           # from aspect-level domain\n","pretrain_embs=                                            # from document-level domain"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RVCkJt6v7kdD","colab_type":"text"},"source":["### LSTM layer (shared between three representations)"]},{"cell_type":"code","metadata":{"id":"meql_fR07kdE","colab_type":"code","colab":{}},"source":["rnn = LSTM(300, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout, name='lstm')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nx18YY_I7kdH","colab_type":"code","colab":{}},"source":["sentence_lstm = rnn(sentence_embs)  #sentence from aspect-level\n","pretrain_lstm = rnn(pretrain_embs)  #sentence from document-level"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jktzwmPI7kdO","colab_type":"code","colab":{}},"source":["# UNCOMMENT REPLACE KEYS?, QUERY? WITH THE CORRESPONDING TENSORS AS ATTENTION KEYS AND QUERY\n","#att_context, att_weights = attention(KEYS?, QUERY?)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7US3khfR7kdZ","colab_type":"code","colab":{}},"source":["pretrain_avg = Average(mask_zero=True)(pretrain_lstm)\n","\n","sentence_output = Dense(num_outputs, name='dense_1')(att_context)\n","pretrain_output = Dense(num_outputs, name='dense_2')(pretrain_avg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-jE8dhm7kde","colab_type":"code","colab":{}},"source":["sentence_output = Reshape((num_outputs,))(sentence_output)   #Shape (Batch-size,1,3)->(Batch-size,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dgKnXfO7kdh","colab_type":"code","colab":{}},"source":["aspect_probs = Activation('softmax', name='aspect_model')(sentence_output)\n","doc_probs = Activation('softmax', name='pretrain_model')(pretrain_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c6ptr7iuWIYT","colab":{}},"source":["model = Model(inputs=[sentence_input, aspect_input, pretrain_input], outputs=[aspect_probs, doc_probs])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bmPSF8IAENj_","colab":{}},"source":["import keras.optimizers as opt\n","\n","optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eiFkEy-eVtoU","outputId":"8e611845-9951-4f35-bcba-a55103743742","colab":{"base_uri":"https://localhost:8080/","height":833}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","sentence_input (InputLayer)     (None, 82)           0                                            \n","__________________________________________________________________________________________________\n","aspect_input (InputLayer)       (None, 7)            0                                            \n","__________________________________________________________________________________________________\n","word_emb (Embedding)            multiple             3000900     aspect_input[0][0]               \n","                                                                 sentence_input[0][0]             \n","                                                                 pretrain_input[0][0]             \n","__________________________________________________________________________________________________\n","aspect_emb (Average)            (None, 300)          0           word_emb[0][0]                   \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     multiple             721200      word_emb[1][0]                   \n","                                                                 word_emb[2][0]                   \n","__________________________________________________________________________________________________\n","repeator_att (RepeatVector)     (None, 82, 300)      0           aspect_emb[0][0]                 \n","__________________________________________________________________________________________________\n","concator_att (Concatenate)      (None, 82, 600)      0           lstm[0][0]                       \n","                                                                 repeator_att[0][0]               \n","__________________________________________________________________________________________________\n","densor1_att (Dense)             (None, 82, 300)      180300      concator_att[0][0]               \n","__________________________________________________________________________________________________\n","densor2_att (Dense)             (None, 82, 1)        301         densor1_att[0][0]                \n","__________________________________________________________________________________________________\n","pretrain_input (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","attention_weights (Activation)  (None, 82, 1)        0           densor2_att[0][0]                \n","__________________________________________________________________________________________________\n","dotor_att (Dot)                 (None, 1, 300)       0           attention_weights[0][0]          \n","                                                                 lstm[0][0]                       \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1, 3)         903         dotor_att[0][0]                  \n","__________________________________________________________________________________________________\n","average_1 (Average)             (None, 300)          0           lstm[1][0]                       \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 3)            0           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 3)            903         average_1[0][0]                  \n","__________________________________________________________________________________________________\n","aspect_model (Activation)       (None, 3)            0           reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","pretrain_model (Activation)     (None, 3)            0           dense_2[0][0]                    \n","==================================================================================================\n","Total params: 3,904,507\n","Trainable params: 3,904,507\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FaNcPdHiC650","colab":{}},"source":["model.compile(optimizer=optimizer,\n","              loss={'aspect_model': 'categorical_crossentropy', 'pretrain_model': 'categorical_crossentropy'},\n","              loss_weights = {'aspect_model': 1, 'pretrain_model': 0.1},\n","              metrics = {'aspect_model': 'categorical_accuracy', 'pretrain_model': 'categorical_accuracy'})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ilIKUGn_DEgB"},"source":["### Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Xi0coTFsDWFG","colab":{}},"source":["batch_size = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5Y3_eO4QgyC3","colab":{}},"source":["train_steps_epoch = len(train_x)/batch_size\n","batch_train_iter = Dataiterator([train_x, train_y, train_aspect], \\\n","                                [pretrain_data, pretrain_label], batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PcKpKWBm7keF","colab_type":"code","colab":{}},"source":["val_steps_epoch = len(dev_x)/batch_size\n","batch_val_iter = Dataiterator([dev_x, dev_y, dev_aspect], \\\n","                              [pretrain_data, pretrain_label], batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXqu6Ho47keJ","colab_type":"code","colab":{}},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","def train_generator(model, batch_train_iter, batch_val_iter):\n","    \n","    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n","                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n","                                     monitor='val_loss', save_best_only=False, \\\n","                                     save_weights_only=True)\n","                     ]\n","    \n","    def train_gen():\n","        while True:\n","            train_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n","                             aspect, pretrain_X, pretrain_y in batch_train_iter]\n","            for train_batch in train_batches:\n","                yield train_batch\n","                \n","    def val_gen():\n","        while True:\n","            val_batches = [[[X, aspect, pretrain_X], [y, pretrain_y]] for X, y, \\\n","                           aspect, pretrain_X, pretrain_y in batch_val_iter]\n","            for val_batch in val_batches:\n","                yield val_batch\n","                \n","    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n","                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n","                                  epochs = 20, callbacks = earlystop_callbacks)\n","      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxAjkoqz7keO","colab_type":"code","outputId":"83e27987-0134-4b69-d02f-7c385d5eda0f","colab":{}},"source":["train_generator(model, batch_train_iter, batch_val_iter)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /home/tita/miniconda3/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /home/tita/miniconda3/envs/tfenv/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Epoch 1/20\n"," 5/57 [=>............................] - ETA: 7:16 - loss: 1.2199 - aspect_model_loss: 1.1142 - pretrain_model_loss: 1.0571 - aspect_model_categorical_accuracy: 0.3750 - pretrain_model_categorical_accuracy: 0.7312"],"name":"stdout"}]}]}