{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Practical 4b.2 (DAE_MNIST).ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VzFq56CczS88","colab_type":"text"},"source":["Code based on: https://blog.keras.io/building-autoencoders-in-keras.html"]},{"cell_type":"code","metadata":{"id":"jIttCorOzS8-","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Flatten, Dense, Reshape\n","from tensorflow.keras import backend as K\n","import matplotlib.pyplot as plt\n","import os\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EPUy7lpezS9D","colab_type":"text"},"source":["# Data (MNIST)\n","Import the MNIST dataset, normalise and reshape it."]},{"cell_type":"code","metadata":{"id":"v61XskcZzS9E","colab_type":"code","colab":{}},"source":["from keras.datasets import mnist\n","import numpy as np\n","\n","(x_train, _), (x_test, _) = mnist.load_data()\n","\n","img_rows, img_cols, chns = 28, 28, 1\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], chns, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], chns, img_rows, img_cols)\n","    input_shape = (chns, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, chns)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, chns)\n","    input_shape = (img_rows, img_cols, chns)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sMA6kkW-zS9I","colab_type":"text"},"source":["### Adding noise\n","We obtain a noisy version of our data by adding Gaussian (normal) noise to each pixel, and clipping pixel values between 0 and 1."]},{"cell_type":"code","metadata":{"id":"UsSUEcg7zS9J","colab_type":"code","colab":{}},"source":["noise_factor = 0.5\n","x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n","x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n","\n","x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n","x_test_noisy = np.clip(x_test_noisy, 0., 1.)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pUl3HlsCzS9O","colab_type":"text"},"source":["Let's visualise some examples from the original test set as well as their noisy version."]},{"cell_type":"code","metadata":{"id":"z5tLNjtpzS9P","colab_type":"code","colab":{}},"source":["def plot_examples(x):\n","    n = 10\n","    plt.figure(figsize=(20, 2))\n","    for i in range(n):\n","        ax = plt.subplot(1, n, i+1)\n","        plt.imshow(x[i].reshape(28, 28))\n","        plt.gray()\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)\n","    plt.show()\n","\n","plot_examples(x_test)\n","plot_examples(x_test_noisy)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B_vdQr_zzS9T","colab_type":"text"},"source":["# Model architecture & settings"]},{"cell_type":"markdown","metadata":{"id":"2UvRGmTjzS9U","colab_type":"text"},"source":["For the encoder we will use convolutional layers and Max-Pooling (to down-sample the image), followed by a Dense layer. This gives a hidden \"code\" of 128 dimensions. For the decoder we use a Dense layer to upscale to the same dimension before convolutional layers and UpSampling. We also include Batch Normalization, which significantly speeds up training.\n","\n","More precisely, for the encoder we will use the following architecture:\n","* Convolutional layer\n","* MaxPooling\n","* Batch Normalization\n","* Convolutional layer\n","* MaxPooling\n","* Batch Normalization\n","* Dense layer\n","\n","From this we obtain a 128-dimensional encoded representation, this is the \"code\" of the autoencoder.\n","\n","The decoder will have the following architecture:\n","* Dense layer (to reshape/upsample to a suitable representation for the next convolutional layer)\n","* Convolutional layer\n","* UpSampling\n","* Batch Normalization\n","* Convolutional layer\n","* UpSampling\n","* Batch Normalization\n","* Convolutional layer (this layer should generate ouput images, of the same format as the input of the encoder)\n","\n","All convolutional layers (except for the output layer) will have 32 filters (feature maps), a kernel size of 3x3, strides of 1x1, \"ReLU\" activations and \"same\" padding. All MaxPooling and UpSampling operations will have size 2x2. To connect a convolutional layer after a Dense layer, use a Reshape layer to transform the data to the right shape for convolutions.\n","\n","The final convolutional layer should produce images in the same format as the input. It will have a kernel size of 3x3, and use \"same\" padding. Think of a suitable activation, and the right number of filters.\n","\n","Optional: output a summary of the architecture.\n","\n","Compile the model to use the \"adam\" optimizer, with a suitable loss function."]},{"cell_type":"code","metadata":{"id":"Emg9bP2WzS9V","colab_type":"code","colab":{}},"source":["# === add code here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QnX8SyMQzS9Z","colab_type":"text"},"source":["# Training the model\n","Train the model (using stochastic gradient descent) with given batch size, for given number of epochs. We split of 1/12-th of the data (5,000 of the 60,000 samples) as validation data, such that we can use the validation accuracy for hyperparameter tuning. Since the model includes batch normalization, we don't need to train for many epochs to achieve reasonable results.\n","\n","Note that we use the noisy data as input and the original data as target, such that the model learns to denoise the data."]},{"cell_type":"code","metadata":{"id":"BKyoBUjbzS9Z","colab_type":"code","colab":{}},"source":["batch_size = 100\n","epochs = 10\n","\n","autoencoder.fit(x_train_noisy, x_train,\n","                batch_size=batch_size,\n","                epochs=epochs,\n","                validation_split=1/12)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MIJd5-LEzS9f","colab_type":"text"},"source":["# Evaluating the model\n","We cannot use an accuracy measure here like in supervised learning, since there are no target labels. We can compute a loss value for the test set, but this doesn't provide an intuitive result. Therefore we will also inspect a few reconstructions visually. First we use the autoencoder to denoise the test set, then we visualise a few examples (the original images, the noisy versions, and their denoised reconstructions)."]},{"cell_type":"code","metadata":{"id":"lSkSqdpdzS9g","colab_type":"code","colab":{}},"source":["test_loss = autoencoder.evaluate(x_test_noisy, x_test, batch_size=batch_size)\n","print(\"Test loss:\", test_loss)\n","\n","x_test_reconstr = autoencoder.predict(x_test_noisy, batch_size=batch_size)\n","\n","plot_examples(x_test)\n","plot_examples(x_test_noisy)\n","plot_examples(x_test_reconstr)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9St6aP6ezS9k","colab_type":"text"},"source":["# Saving the model\n","We save the model to a .h5 file, such that we can load it later in other notebooks."]},{"cell_type":"code","metadata":{"id":"AuZDB-RmHK9C","colab_type":"code","colab":{}},"source":["# mount google drive, so that we can save our model there\n","from google.colab import drive\n","!mkdir drive\n","drive.mount('drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOIuOEmMKrHZ","colab_type":"code","colab":{}},"source":["model_path=os.path.join(\"drive\",\"My Drive\",\"models\")\n","if not os.path.exists(model_path) :              \n","    os.makedirs(model_path)\n","autoencoder.save(os.path.join(model_path,\"dae_mnist.h5\"))"],"execution_count":0,"outputs":[]}]}