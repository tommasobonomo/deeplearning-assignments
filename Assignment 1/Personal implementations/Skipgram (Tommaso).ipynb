{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Skipgram (Tommaso).ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"R3ktsQv8Mkp1","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","\n","from typing import List, Tuple, Union\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, Flatten"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tiKVB-NaMkqD","colab_type":"text"},"source":["# Skipgram\n","\n","Implementation of the Skipgram algorithm for word embeddings"]},{"cell_type":"markdown","metadata":{"id":"CUb52qcHMkqG","colab_type":"text"},"source":["### Preprocessing"]},{"cell_type":"code","metadata":{"id":"64-vUMKMQ4GX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"c3d301d5-cb89-4d58-a804-c6035f99e84f","executionInfo":{"status":"ok","timestamp":1589276565731,"user_tz":-120,"elapsed":21046,"user":{"displayName":"Tommaso Bonomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFvz9TYkjc3qXXXhAwietnkHUX96TSaQl2pAP15Q=s64","userId":"12850357366043369607"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DIuYh-ybQ_eS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"77d8a1e5-d692-49ec-986c-b3735aab51e0","executionInfo":{"status":"ok","timestamp":1589276590482,"user_tz":-120,"elapsed":1121,"user":{"displayName":"Tommaso Bonomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFvz9TYkjc3qXXXhAwietnkHUX96TSaQl2pAP15Q=s64","userId":"12850357366043369607"}}},"source":["cd \"/content/drive/My Drive/deep learning (Tommaso)\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1Uhw8IQungyqnlJEo9yI6DY9h6yWgz8bk/deep learning (Tommaso)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7bO9g-bDMkqM","colab_type":"code","colab":{}},"source":["with open(\"alice.txt\", \"r\") as f:\n","    raw_corpus = f.readlines()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"27YHaPPoMkqV","colab_type":"code","colab":{}},"source":["tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n' + \"'\")\n","tokenizer.fit_on_texts(raw_corpus)\n","corpus = sum((tokenizer.texts_to_sequences(raw_corpus)), [])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AeFSc2IBMkqe","colab_type":"code","colab":{}},"source":["voc_size = max(corpus) + 1\n","corpus_size = len(corpus)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sG2ISgDMkqn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"23927b4c-ca2c-407b-fba1-4b11ccf5d3dd","executionInfo":{"status":"ok","timestamp":1589276599498,"user_tz":-120,"elapsed":706,"user":{"displayName":"Tommaso Bonomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFvz9TYkjc3qXXXhAwietnkHUX96TSaQl2pAP15Q=s64","userId":"12850357366043369607"}}},"source":["corpus_size, voc_size"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(27330, 2568)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"vDCIK7xaMkqy","colab_type":"text"},"source":["### Dataset generation\n","\n","Skipgram is trained on the following task: given a `window_size`, samples randomly a `word_range` between `1` and `window_size` and tries to guess each word `word_range` around the current word.\n","So we need to construct a dataset of pairs `(word, target)` for each word in the corpus."]},{"cell_type":"code","metadata":{"id":"Cd6BkZ6IMkqz","colab_type":"code","colab":{}},"source":["def generate_dataset(\n","    corpus: List[int],\n","    window_size: int,\n","    seed: int = 4322\n",") -> Tuple[np.ndarray, np.ndarray]:\n","    rand_generator = np.random.default_rng(seed=seed)\n","    \n","    x: List[int] = []\n","    y: List[int] = []    \n","    for idx, word in enumerate(corpus):\n","        word_range = rand_generator.integers(1, window_size, endpoint=True)\n","        \n","        surrounding_words = corpus[idx - word_range : idx] + corpus[idx + 1 : idx + word_range + 1]\n","        x += [word] * len(surrounding_words)\n","        y += surrounding_words\n","        \n","    \n","    np_x = np.array(x)\n","    np_y = np.array(y)\n","    \n","    return np_x, np_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RJ7NFb7EMkq8","colab_type":"code","colab":{}},"source":["window_size = 10\n","x, y = generate_dataset(corpus, window_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CpNeWOwTMkrA","colab_type":"text"},"source":["### Skipgram implementation\n","\n","Now we implement the skipgram model, should have quite a simple architecture."]},{"cell_type":"code","metadata":{"id":"4nWGLIkGMkrC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":260},"outputId":"c178803b-7eaf-47b8-f20e-97cf5cebe666","executionInfo":{"status":"ok","timestamp":1589277396715,"user_tz":-120,"elapsed":1109,"user":{"displayName":"Tommaso Bonomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFvz9TYkjc3qXXXhAwietnkHUX96TSaQl2pAP15Q=s64","userId":"12850357366043369607"}}},"source":["embeddding_size = 100\n","skipgram = Sequential([\n","    Embedding(voc_size, embeddding_size, input_length=1),\n","    Flatten(),\n","    Dense(voc_size, activation=\"softmax\", use_bias=False, kernel_regularizer=\"l2\")\n","])\n","\n","skipgram.compile(\n","    optimizer=\"adam\",\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","skipgram.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 1, 100)            256800    \n","_________________________________________________________________\n","flatten (Flatten)            (None, 100)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 2568)              256800    \n","=================================================================\n","Total params: 513,600\n","Trainable params: 513,600\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aHjh0KqQMkrJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"bbf8e513-28ad-4aa1-8aa7-3d4ea8e958c3","executionInfo":{"status":"ok","timestamp":1589277609100,"user_tz":-120,"elapsed":212623,"user":{"displayName":"Tommaso Bonomo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFvz9TYkjc3qXXXhAwietnkHUX96TSaQl2pAP15Q=s64","userId":"12850357366043369607"}}},"source":["_ = skipgram.fit(x, y, batch_size=32, epochs=3)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","9410/9410 [==============================] - 72s 8ms/step - loss: 6.8351 - accuracy: 0.0587\n","Epoch 2/3\n","9410/9410 [==============================] - 69s 7ms/step - loss: 6.4465 - accuracy: 0.0597\n","Epoch 3/3\n","9410/9410 [==============================] - 69s 7ms/step - loss: 6.3623 - accuracy: 0.0592\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7yjx0bybMkrR","colab_type":"text"},"source":["## Evaluation of embeddings"]},{"cell_type":"markdown","metadata":{"id":"i88hZMd7MkrS","colab_type":"text"},"source":["We first get the embedding layer from the model"]},{"cell_type":"code","metadata":{"id":"2JA5CmTxMkrU","colab_type":"code","colab":{}},"source":["embedding_layer = skipgram.layers[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IgXuIAbiMkre","colab_type":"text"},"source":["We then define a function to retrieve the embedding of a word. Can pass custom tokenizer or embedding_layer, but will otherwise use what we defined\n","above."]},{"cell_type":"code","metadata":{"id":"I5FJSGMvMkrf","colab_type":"code","colab":{}},"source":["def embed(\n","    word: str,\n","    tokenizer: Tokenizer = tokenizer,\n","    embedding_layer: Embedding = embedding_layer\n",") -> np.ndarray:\n","    word_index = tokenizer.texts_to_sequences([word])\n","    output_tensor = embedding_layer(np.array(word_index))\n","    return tf.reshape(output_tensor, (-1, 1))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"584NKhx_Mkrq","colab_type":"text"},"source":["We also define a function that retrieves the closes word to a word vector"]},{"cell_type":"code","metadata":{"id":"XAe5wCv4Mkrs","colab_type":"code","colab":{}},"source":["def cosine_similarity(\n","    v: Union[np.ndarray, tf.Tensor],\n","    w: Union[np.ndarray, tf.Tensor]) -> float:\n","    \"\"\"v and w should be 1D-vectors, for which to calculate the cosine similarity\"\"\"\n","    \n","    assert isinstance(v, tf.Tensor) or isinstance(v, np.ndarray), \"v must be tf.Tensor or np.ndarray\"\n","    assert isinstance(w, tf.Tensor) or isinstance(w, np.ndarray), \"w must be tf.Tensor or np.ndarray\"\n","    \n","    v = v.numpy() if isinstance(v, tf.Tensor) else v\n","    w = w.numpy() if isinstance(w, tf.Tensor) else w\n","    \n","    if v.ndim > 1:\n","        v = v.flatten()\n","    if w.ndim > 1:\n","        w = w.flatten()\n","\n","    return v @ w.T / (np.linalg.norm(v) * np.linalg.norm(w))\n","    \n","def closest_n_words(\n","    embedding: tf.Tensor,\n","    n: int = 1,\n","    tokenizer: Tokenizer = tokenizer,\n","    embedding_layer: Embedding = embedding_layer\n",") -> List[str]:    \n","    all_words = np.array(list(tokenizer.index_word.values()))\n","    all_embeddings = np.array([embed(word).numpy() for word in all_words]).squeeze()\n","    similarities = np.apply_along_axis(\n","        lambda row: cosine_similarity(row, embedding),\n","        1, all_embeddings\n","    )\n","    sorted_idx = np.argsort(similarities)\n","    \n","    return np.flip(all_words[sorted_idx[-n:]]).tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5CZ39kxmMkrx","colab_type":"text"},"source":["Ideally, we might think that $e_\\text{king} - e_\\text{man} \\approx e_\\text{queen} - e_\\text{woman}$. So if we try and find the closest word to \n","$e_\\text{king} - e_\\text{queen} + e_\\text{woman}$ it should be close to $e_\\text{man}$"]},{"cell_type":"code","metadata":{"id":"5UvspY2HMkrz","colab_type":"code","colab":{}},"source":["analogy = embed(\"king\") - embed(\"queen\") + embed(\"woman\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bN60Nk5pMkr6","colab_type":"code","colab":{},"outputId":"133f2a8c-c754-40c3-d472-da038c126bb0"},"source":["closest_n_words(analogy, 10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['old',\n"," 'remarked',\n"," 'your',\n"," 'myself',\n"," 'talk',\n"," 'are',\n"," 'd',\n"," 'believe',\n"," 'we',\n"," 'show']"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"xViwHOIMMksB","colab_type":"code","colab":{},"outputId":"277ae5ea-2661-49ee-fa1f-f2135e8c9281"},"source":["cosine_similarity(analogy, embed(\"man\"))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.98229545"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"_34W7twqVDci","colab_type":"code","colab":{}},"source":["all_words = np.array(list(tokenizer.index_word.values()))\n","all_embeddings = np.array([embed(word).numpy() for word in all_words]).squeeze()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpJUu-KDVEUB","colab_type":"code","colab":{}},"source":["str_embeddings = all_embeddings.astype(\"str\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qc8NmmgXZb7a","colab_type":"code","colab":{}},"source":["with open(\"skipgrams_embeddings.tsv\", \"w\") as f:\n","    for line in str_embeddings:\n","        f.write(\"\\t\".join(line) + \"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Sel17xmoa8ne","colab":{}},"source":["with open(\"skipgram_meta.tsv\", \"w\") as f:\n","    for word in all_words:\n","        f.write(f\"{word}\\n\")"],"execution_count":0,"outputs":[]}]}