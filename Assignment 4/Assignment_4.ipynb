{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByN2rzPmnk_3",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4: Anomaly Detection with VAEs\n",
        "As we have seen, Variational Autoencoders (VAEs) provide a mathematically grounded framework for the unsupervised learning of latent representations. Besides interpreting VAEs as representation learning or generative modelling, we can also see them as performing (approximate) density approximation. VAEs are trained to optimise a lower bound to the (log) likelihood $\\log p(X)$ of the data $X$, under the chosen model. So, for any point in data space, we can obtain an estimate of its likelihood under the trained model, by simply computing the loss function when passing this data point through the neural network (note that the loss function is the negative ELBO, so we need to multiply by -1 to obtain a likelihood estimation).\n",
        "\n",
        "We can use this idea to perform unsupervised anomaly detection. Suppose we are given a dataset that describes some natural distribution (e.g. images of certain clothing items). For new test data, we then wish to detect whether it fits this distribution, or is significantly different (an anomaly). For example, given a dataset of shirts, we want to detect anomalies in a test data set that also contains some images of trousers. Typically, such a situation occurs when we have many examples of one class (e.g. shirts), but very few of others (the anomalies, e.g. trousers).\n",
        "\n",
        "In this task, we will perform and evaluate such anomaly detection with VAEs. Given a training data set that consists of instances that we consider \"normal\", we wish to detect anomalies in a test data set that contains both \"normal\" (but unseen) examples, as well as other examples which we consider anomalous. The idea is to train a VAE on the training data, such that it learns to represent \"normal\" data well. We can then compute the ELBO values for the test data, where ideally \"normal\" examples should obtain higher likelihood values than anomalous examples.\n",
        "\n",
        "In this assignment, we will use FashionMNIST to simulate the anomaly detection task. We will omit one class from the training data, and consider the remaining 9 classes to be \"normal\". The goal is then to identify the omitted class in the test data, by comparing the ELBO values obtained from a VAE trained on 9 classes.\n",
        "\n",
        "**NOTE:**\n",
        "* **Only fill in the cells marked with `#### INSERT CODE HERE ####` or `<-- WRITE TEXT HERE -->`**\n",
        "* **Do not add or delete any cells**\n",
        "* **Make sure to run all cells before handing in.**\n",
        "* **Re-running all cells in your notebook in order should produce similar output (it may vary slightly due to stochasticity in the training).**\n",
        "* **You don't need to extensively comment your code, but briefly mention any assumptions you make, or any design choices.**\n",
        "* **Make sure that the cell output (where needed) is clear and easy to interpret (i.e. print what it is you are outputting, captions/titles for plots).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9ZKPPpjqUN8",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "These should be all the imports you'll need, please don't use any other libraries as this will make it harder to assess your work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntW-85FLp_u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNcawSBPqDso",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Obtain anomaly detection dataset\n",
        "**(a)** We will consider the \"Trouser\" class (with label 1) to be the anomalies, and consider the other 9 classes to be our \"normal\" data. We'll train on normal data only, but we want to test on both normal and anomalous data to evaluate our anomaly detection framework.\n",
        "* Load the FashionMNIST dataset.\n",
        "* Remove all instances from the anomaly class from the training set.\n",
        "* Split the test set in two parts: the anomalous data (with label 1) and the normal data (all other labels).\n",
        "\n",
        "*Implementation hint: `np.argwhere` may be helpful for splitting the data based on its labels.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8bN-iROqZkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baX5agom85h9",
        "colab_type": "text"
      },
      "source": [
        "**(b)** To check if the split was done correctly, plot some random examples (at least 10 each) of:\n",
        "* The new training set (without the anomaly class)\n",
        "* The normal test set\n",
        "* The anomaly test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQo9Q7aH4v7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diAw1AsInohM",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: Design, implement, and train a VAE\n",
        "**(a)** Design a VAE for the FashionMNIST dataset with a suitable architecture, that should perform well on this dataset.\n",
        "* Implement the VAE (with corresponding loss functions) and compile it.\n",
        "* Print a summary (with `.summary()`) of the encoder and decoder.\n",
        "\n",
        "*Hint: in Practical 6.1 we used a latent dimension of 2 because it allows for nice latent space plots. This limits the capacity of the VAE however, so here you will want to choose a higher number.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO_O7vggnrNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRvM8Ye4_QG3",
        "colab_type": "text"
      },
      "source": [
        "**(b)** Train the VAE on the FashionMNIST training dataset without the anomaly class. Make sure that you train long enough such that the loss is no longer going down. Make sure that the training output is printed (use the default `verbose` setting in `.fit`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q-urWun4zm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l13BYKtnrdF",
        "colab_type": "text"
      },
      "source": [
        "## Task 3: Inspect VAE performance\n",
        "Qualitatively inspect if the VAE is trained well. The latent space plots we saw in the practical only work for 2-dimensional latent spaces, but you may need to increase the dimensionality of the latent space for good performance. Therefore we'll make some plots that work for higher-dimensional latent spaces as well; reconstructions and random samples:\n",
        "\n",
        "* __Reconstructions:__ Take a random sample of normal training images (at least 10), and use the VAE to obtain their reconstructions. Plot both originals and reconstructions, on top of each other.\n",
        "* __Random samples:__ Randomly generate some images (at least 10) with the VAE; i.e. sample latent variables from the prior distribution, and decode them into data space. Plot the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEAyATtMntyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i0DcHz_nuI9",
        "colab_type": "text"
      },
      "source": [
        "## Task 4: Anomaly detection\n",
        "**(a)** Use the VAE to obtain density/likelihood estimations for the normal and anomalous test sets, i.e. compute the ELBO (the negative of the loss function) for all points in both test sets. Make sure to keep the scores for the normal and anomaly sets separate from each other.\n",
        "\n",
        "*Implementation hint: Unfortunately, Keras's `.evaluate()` does not allow to access the loss values of individual samples, it only returns the average loss over the entire input. A simple (but slow) workaround is to just use for loops over the entire input and use `.evaluate()` for each data point individually (set `verbose=0` to avoid a long output).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR-Q5LCm42xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cH3GFF9HLuD",
        "colab_type": "text"
      },
      "source": [
        "**(b)** Visualise the scores in a histogram (`plt.hist()`) as well as a density plot (`sns.kdplot` from the `seaborn` library). Use two different colours: **green** for normal data, **red** for anomalous data, and show both normal and anomalous scores in the same plot (use transparency to make visualisation clearer), i.e. one figure with both histograms, and one figure with both density plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0T2Gcbu46nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjkseaL0HMOB",
        "colab_type": "text"
      },
      "source": [
        "**(c)** Given these likelihood scores, we can choose a threshold and classify all instances with a likelihood below the threshold as anomalies, and all instances with a likelihood above the threshold as \"normal\". Different thresholds will give different True/False Positive/Negative scores. We can summarise the performance of all thresholds in an ROC curve, or a Precision-Recall curve (the latter has been shown to be more suitable for imbalanced datasets, see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349800/).\n",
        "* Plot an ROC curve for your results, compute and show the Area Under Curve (AUC) score for quantitative evaluation.\n",
        "* Plot a Precision-Recall curve for your results, compute and show the Area Under Curve (AUC) score for quantitative evaluation.\n",
        "\n",
        "*Implementation hints:*\n",
        "* *See https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/ for more information about ROC and PR curves and their implementation with `sklearn`.*\n",
        "* *ROC/PR curves are typically used for binary classification. You can define anomaly as label 0 and normal as 1, and rescale the ELBO scores from part (a) to be between 0 and 1 (by using the minimum and maximum values in your ELBO results) to express them as binary classification probabilities.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zBelWbKsLzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztjzIMkAVU8Z",
        "colab_type": "text"
      },
      "source": [
        "**(d)** Ideally, a successful VAE for anomaly detection should represent (and thus reconstruct) normal data very well, but not anomalous data. Reconstruct some random images (at least 10 each) from the normal test set, as well as from the anomaly test set. Show the original images and their reconstructions on top of each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAishURfdqVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### INSERT CODE HERE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx_B3pllRFvx",
        "colab_type": "text"
      },
      "source": [
        "**(e)** Give a detailed discussion of your results; does the anomaly detection perform well? Why do you think so? What could be improved? Discuss each of the results from parts (b), (c), and (d) separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bmZfWUl_8Hi",
        "colab_type": "text"
      },
      "source": [
        "<-- WRITE TEXT HERE -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYPZ9HH_jkR2",
        "colab_type": "text"
      },
      "source": [
        "## Task 5: Peer review\n",
        "Finally, each group member must write a single paragraph outlining their opinion on the work distribution within the group. Did every group member contribute equally? Did you split up tasks in a fair manner, or jointly work through the exercises? Do you think that some members of your group deserve a different grade from others?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zNWJVarjj5u",
        "colab_type": "text"
      },
      "source": [
        "<-- WRITE TEXT HERE -->"
      ]
    }
  ]
}